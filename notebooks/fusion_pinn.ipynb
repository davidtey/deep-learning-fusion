{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PINN Implementation of Ashourvan & Diamond Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import grad\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 1.0     # not provided by paper, need to check relation with Λ \n",
    "α = 6.0\n",
    "D_c = 0.78\n",
    "C_χ = 0.95\n",
    "a_u = 1.0\n",
    "μ_c = 0.78\n",
    "β = 0.1\n",
    "Λ = 4000.0\n",
    "ϵ_c = 6.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_i = 5.1\n",
    "ϵ_i = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_params = {\n",
    "    'l': l,\n",
    "    'α': α,\n",
    "    'D_c': D_c,\n",
    "    'C_χ': C_χ,\n",
    "    'a_u': a_u,\n",
    "    'μ_c': μ_c,\n",
    "    'β': β,\n",
    "    'Λ': Λ,\n",
    "    'ϵ_c': ϵ_c,\n",
    "    'g_i': g_i,\n",
    "    'ϵ_i': ϵ_i\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define PDEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define repeated calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_w(C_χ, l, ϵ, α, a_u, u):\n",
    "    return C_χ * l**2 * ϵ / torch.sqrt(α**2 + a_u * u**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic equation for mean density\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pde_mean_density(x, n_t, n_x, n_xx, ϵ, l, α, D_c):    \n",
    "    intermediate = l**2 * ϵ * n_x / α\n",
    "    intermediate_x = grad(intermediate, x, grad_outputs=torch.ones_like(intermediate), retain_graph=True, create_graph=True)[0]\n",
    "    \n",
    "    return (n_t - intermediate_x - D_c * n_xx)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic equation for mean vorticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pde_mean_vorticity(x, ϵ, n_x, u_t, u_xx, l, α, μ_c, w):    \n",
    "    intermediate = (l**2 * ϵ / α - w) * n_x\n",
    "    intermediate_x = grad(intermediate, x, grad_outputs=torch.ones_like(intermediate), retain_graph=True, create_graph=True)[0]\n",
    "    \n",
    "    return (u_t - intermediate_x - w * u_xx - μ_c * u_xx)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic equation for turbulent potential entrosphy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pde_tpe(x, ϵ, n_x, u_x, ϵ_t, ϵ_x, l, β, Λ, ϵ_c, w):\n",
    "    intermediate = l**2 * torch.sqrt(ϵ) * ϵ_x\n",
    "    intermediate_x = grad(intermediate, x, grad_outputs=torch.ones_like(intermediate), retain_graph=True, create_graph=True)[0]\n",
    "    \n",
    "    return (ϵ_t - β * intermediate_x - Λ * (w * (n_x - u_x)**2 - ϵ**(3/2) / ϵ_c**0.5 + ϵ))**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Initial Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_initial_cond(t, x):\n",
    "    return torch.max(-g_i * x)\n",
    "\n",
    "def u_initial_cond(t, x):\n",
    "    return torch.max(torch.zeros(x.shape, device=x.device.type))\n",
    "\n",
    "def ϵ_initial_cond(t, x):\n",
    "    return torch.max(torch.full(x.shape, ϵ_i, device=x.device.type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Boundary Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_boundary_cond(t, x):\n",
    "    out = torch.full(x.shape, -g_i, device=x.device.type)\n",
    "    out = out * x\n",
    "    \n",
    "    return torch.max(out)\n",
    "\n",
    "def u_boundary_cond(t, x):\n",
    "    return torch.max(torch.zeros(x.shape, device=x.device.type))\n",
    "\n",
    "\n",
    "def ϵ_x_boundary_cond(t, x):\n",
    "    return torch.max(torch.zeros(x.shape, device=x.device.type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PINN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOutputLayer(nn.Module):\n",
    "    def __init__(self, pars):\n",
    "        super(CustomOutputLayer, self).__init__()\n",
    "        self.n = nn.Sequential(nn.Linear(pars['width'], 1))\n",
    "        self.u = nn.Sequential(nn.Linear(pars['width'], 1))\n",
    "        self.ϵ = nn.Sequential(nn.Linear(pars['width'], 1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.hstack((self.n(x), self.u(x), torch.abs(self.ϵ(x) + 1e-2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    def __init__(self, pars: dict):\n",
    "        super().__init__()\n",
    "        self.pars = pars\n",
    "        \n",
    "        self.modules = [nn.BatchNorm1d(2), nn.Linear(2, self.pars['width'])] # nn.LayerNorm(2)\n",
    "        for i in range(self.pars['layers'] - 1):\n",
    "            # self.modules.append(nn.LayerNorm(self.pars['width']))\n",
    "            self.modules.append(nn.GELU())\n",
    "            self.modules.append(nn.Linear(self.pars['width'], self.pars['width']))\n",
    "        \n",
    "        # self.modules.append(nn.LayerNorm(self.pars['width']))\n",
    "        self.modules.append(CustomOutputLayer(pars))\n",
    "        \n",
    "        self.model = nn.Sequential(*self.modules)\n",
    "        self.model.to(self.pars['device'])\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(params=self.model.parameters(), lr=self.pars['lr'])\n",
    "        self.num_params = sum([len(params) for params in [p for p in self.model.parameters()]])\n",
    "        \n",
    "        self.epoch = 0\n",
    "        \n",
    "        t = np.linspace(self.pars['t_min'], self.pars['t_max'], 100)\n",
    "        x = np.linspace(self.pars['x_min'], self.pars['x_max'], 100)\n",
    "\n",
    "        self.eval_t, self.eval_x = np.meshgrid(t, x)\n",
    "        self.eval_t = torch.Tensor(self.eval_t).reshape(-1, 1).to(self.pars['device'])\n",
    "        self.eval_x = torch.Tensor(self.eval_x).reshape(-1, 1).to(self.pars['device'])\n",
    "        \n",
    "        self.eval_t.requires_grad_()\n",
    "        self.eval_x.requires_grad_()\n",
    "        \n",
    "        eval_t_interior, eval_x_interior = np.meshgrid(t[1:-1], x[1:-1])\n",
    "        eval_t_interior = torch.Tensor(eval_t_interior).reshape(-1, 1).to(self.pars['device'])\n",
    "        eval_x_interior = torch.Tensor(eval_x_interior).reshape(-1, 1).to(self.pars['device'])\n",
    "        \n",
    "        self.eval_X_interior = torch.hstack((eval_t_interior, eval_x_interior))\n",
    "        self.eval_X_interior.requires_grad_()\n",
    "        \n",
    "        eval_t_initial = torch.zeros_like(self.eval_x)\n",
    "        self.eval_X_initial = torch.hstack((eval_t_initial, self.eval_x))\n",
    "        self.eval_X_initial.requires_grad_()\n",
    "        \n",
    "        eval_t_boundary = torch.Tensor(np.vstack([t, t])).reshape(-1, 1).to(self.pars['device'])\n",
    "        eval_x_boundary = torch.Tensor(np.vstack([x[0] * np.ones_like(t), x[-1] * np.ones_like(t)])).reshape(-1, 1).to(self.pars['device'])\n",
    "        \n",
    "        self.eval_X_boundary = torch.hstack((eval_t_boundary, eval_x_boundary))\n",
    "        self.eval_X_boundary.requires_grad_()\n",
    "        \n",
    "        self.plot_t = self.eval_t.view(100, 100).detach().cpu().numpy()\n",
    "        self.plot_x = self.eval_x.view(100, 100).detach().cpu().numpy()\n",
    "        \n",
    "        self.plot_files = {}\n",
    "        \n",
    "        if 'plot_vars_list' in self.pars:\n",
    "            for varname in self.pars['plot_vars_list']:\n",
    "                self.plot_files[varname] = []\n",
    "        \n",
    "    def __call__(self, X):\n",
    "        return self.model(X)\n",
    "        \n",
    "    def sample_interior_points(self):\n",
    "        t = torch.empty((self.pars['interior_batch_size'], 1), device=self.pars['device']).uniform_(self.pars['t_min'], self.pars['t_max'])\n",
    "        x = torch.empty((self.pars['interior_batch_size'], 1), device=self.pars['device']).uniform_(self.pars['x_min'], self.pars['x_max'])\n",
    "        X_interior = torch.cat((t, x), 1)\n",
    "        X_interior.requires_grad_()\n",
    "        \n",
    "        return X_interior\n",
    "    \n",
    "    def sample_initial_points(self):\n",
    "        t = torch.zeros(self.pars['initial_batch_size'], 1, device=self.pars['device'])\n",
    "        x = torch.empty((self.pars['initial_batch_size'], 1), device=self.pars['device']).uniform_(self.pars['x_min'], self.pars['x_max'])\n",
    "        X_initial = torch.cat((t, x), 1)\n",
    "        X_initial.requires_grad_()\n",
    "        \n",
    "        return X_initial\n",
    "    \n",
    "    def sample_boundary_points(self):\n",
    "        options = torch.tensor([self.pars['x_min'], self.pars['x_max']], device=self.pars['device'])\n",
    "        \n",
    "        t = torch.empty((self.pars['boundary_batch_size'], 1), device=self.pars['device']).uniform_(self.pars['t_min'], self.pars['t_max'])\n",
    "        x = options[torch.randint(0, 2, (self.pars['boundary_batch_size'], 1), device=self.pars['device'])]\n",
    "        X_boundary = torch.cat((t, x), 1)\n",
    "        X_boundary.requires_grad_()\n",
    "        \n",
    "        return X_boundary\n",
    "    \n",
    "    def forward(self, X_interior, X_initial, X_boundary):\n",
    "        # X shape: (batch_size, 2), where 2nd dimension is [t, x]\n",
    "        # Y shape: (batch_size, 3), where 2nd dimension is [n, u, ϵ]\n",
    "        \n",
    "        t_interior = X_interior[:, 0].reshape(-1, 1)\n",
    "        x_interior = X_interior[:, 1].reshape(-1, 1)\n",
    "        t_initial = X_initial[:, 0].reshape(-1, 1)\n",
    "        x_initial = X_initial[:, 1].reshape(-1, 1)\n",
    "        t_boundary = X_boundary[:, 0].reshape(-1, 1)\n",
    "        x_boundary = X_boundary[:, 1].reshape(-1, 1)\n",
    "        \n",
    "        # forward pass\n",
    "        Y_interior = self.model(torch.hstack((t_interior, x_interior)))\n",
    "        Y_initial = self.model(torch.hstack((t_initial, x_initial)))\n",
    "        Y_boundary = self.model(torch.hstack((t_boundary, x_boundary)))\n",
    "        \n",
    "        n_interior = Y_interior[:, 0].reshape(-1, 1)\n",
    "        u_interior = Y_interior[:, 1].reshape(-1, 1)\n",
    "        ϵ_interior = Y_interior[:, 2].reshape(-1, 1)\n",
    "        \n",
    "        n_initial = Y_initial[:, 0].reshape(-1, 1)\n",
    "        u_initial = Y_initial[:, 1].reshape(-1, 1)\n",
    "        ϵ_initial = Y_initial[:, 2].reshape(-1, 1)\n",
    "        \n",
    "        n_boundary = Y_boundary[:, 0].reshape(-1, 1)\n",
    "        u_boundary = Y_boundary[:, 1].reshape(-1, 1)\n",
    "        ϵ_boundary = Y_boundary[:, 2].reshape(-1, 1)\n",
    "        \n",
    "        n_x_interior = grad(n_interior, x_interior, grad_outputs=torch.ones_like(n_interior), retain_graph=True, create_graph=True)[0]\n",
    "        n_t_interior = grad(n_interior, t_interior, grad_outputs=torch.ones_like(n_interior), retain_graph=True, create_graph=True)[0]\n",
    "        \n",
    "        n_xx_interior = grad(n_x_interior, x_interior, grad_outputs=torch.ones_like(n_x_interior), retain_graph=True, create_graph=True)[0]\n",
    "        \n",
    "        u_x_interior = grad(u_interior, x_interior, grad_outputs=torch.ones_like(u_interior), retain_graph=True, create_graph=True)[0]\n",
    "        u_t_interior = grad(u_interior, t_interior, grad_outputs=torch.ones_like(u_interior), retain_graph=True, create_graph=True)[0]\n",
    "        \n",
    "        u_xx_interior = grad(u_x_interior, x_interior, grad_outputs=torch.ones_like(u_x_interior), retain_graph=True, create_graph=True)[0]\n",
    "        \n",
    "        ϵ_x_interior = grad(ϵ_interior, x_interior, grad_outputs=torch.ones_like(ϵ_interior), retain_graph=True, create_graph=True)[0]\n",
    "        ϵ_t_interior = grad(ϵ_interior, t_interior, grad_outputs=torch.ones_like(ϵ_interior), retain_graph=True, create_graph=True)[0]\n",
    "        \n",
    "        ϵ_x_boundary = grad(ϵ_boundary, x_boundary, grad_outputs=torch.ones_like(ϵ_boundary), retain_graph=True, create_graph=True)[0]\n",
    "        \n",
    "        w = compute_w(C_χ, l, ϵ_interior, α, a_u, u_interior)\n",
    "        \n",
    "        density_loss = pde_mean_density(x_interior, n_t_interior, n_x_interior, n_xx_interior, ϵ_interior, l, α, D_c).mean()\n",
    "        vorticity_loss = pde_mean_vorticity(x_interior, ϵ_interior, n_x_interior, u_t_interior, u_xx_interior, l, α, μ_c, w).mean()\n",
    "        tpe_loss = pde_tpe(x_interior, ϵ_interior, n_x_interior, u_x_interior, ϵ_t_interior, ϵ_x_interior, l, β, Λ, ϵ_c, w).mean()\n",
    "        interior_loss = (density_loss + vorticity_loss + tpe_loss)/3\n",
    "        \n",
    "        mse = nn.MSELoss()\n",
    "        \n",
    "        initial_n_loss = mse(n_initial_cond(t_initial, x_initial), n_initial)\n",
    "        initial_u_loss = mse(u_initial_cond(t_initial, x_initial), u_initial)\n",
    "        initial_ϵ_loss = mse(ϵ_initial_cond(t_initial, x_initial), ϵ_initial)\n",
    "        initial_loss = (initial_n_loss + initial_u_loss + initial_ϵ_loss)/3\n",
    "        \n",
    "        boundary_n_loss = mse(n_boundary_cond(t_boundary, x_boundary), n_boundary)\n",
    "        boundary_u_loss = mse(u_boundary_cond(t_boundary, x_boundary), u_boundary)\n",
    "        boundary_ϵ_loss = mse(ϵ_x_boundary_cond(t_boundary, x_boundary), ϵ_x_boundary)\n",
    "        boundary_loss = (boundary_n_loss + boundary_u_loss + boundary_ϵ_loss)/3\n",
    "        total_loss = interior_loss + initial_loss + boundary_loss\n",
    "        \n",
    "        return total_loss, density_loss, vorticity_loss, tpe_loss, initial_n_loss, initial_u_loss, initial_ϵ_loss, boundary_n_loss, boundary_u_loss, boundary_ϵ_loss\n",
    "    \n",
    "    def train(self):\n",
    "        cwd = os.getcwd()\n",
    "        plot_dirs = os.path.join(cwd, f'plots/{self.pars[\"experiment_name\"]}')\n",
    "\n",
    "        if not os.path.isdir(plot_dirs):\n",
    "            os.makedirs(plot_dirs)\n",
    "        \n",
    "        mlflow.set_experiment(self.pars['experiment_name'])\n",
    "        mlflow.start_run()\n",
    "        \n",
    "        mlflow.log_param(\"physical_params\", physical_params)\n",
    "        mlflow.log_param(\"model_params\", self.pars)\n",
    "        \n",
    "        for epoch in tqdm(range(self.pars['epochs']), position=0, leave=True, desc='Training...'): \n",
    "            self.epoch = epoch\n",
    "            \n",
    "            # eval\n",
    "            if epoch % self.pars['eval_interval'] == 0 or epoch == self.pars['epochs'] - 1:\n",
    "                \n",
    "                loss, density_loss, vorticity_loss, tpe_loss, initial_n_loss, initial_u_loss, initial_ϵ_loss, boundary_n_loss, boundary_u_loss, boundary_ϵ_loss \\\n",
    "                    = self.forward(self.eval_X_interior, self.eval_X_initial, self.eval_X_boundary)\n",
    "                \n",
    "                print()\n",
    "                print(f'Epoch: {self.epoch}, Loss: {loss.item():,.4e}')\n",
    "                print(f\"density_loss: {density_loss.item():.4e}, vorticity_loss: {vorticity_loss.item():.4e}, tpe_loss: {tpe_loss.item():.4e}\")\n",
    "                print(f\"initial_n_loss: {initial_n_loss.item():.4e}, initial_u_loss: {initial_u_loss.item():.4e}, initial_ϵ_loss: {initial_ϵ_loss.item():.4e}\")\n",
    "                print(f\"boundary_n_loss: {boundary_n_loss.item():.4e}, boundary_u_loss: {boundary_u_loss.item():.4e}, boundary_ϵ_loss: {boundary_ϵ_loss.item():.4e}\")\n",
    "                \n",
    "                mlflow.log_metric(\"total_loss\", loss.item(), step=self.epoch)\n",
    "                mlflow.log_metric(\"density_loss\", density_loss.item(), step=self.epoch)\n",
    "                mlflow.log_metric(\"vorticity_loss\", vorticity_loss.item(), step=self.epoch)\n",
    "                mlflow.log_metric(\"tpe_loss\", tpe_loss.item(), step=self.epoch)\n",
    "                mlflow.log_metric(\"initial_n_loss\", initial_n_loss.item(), step=self.epoch)\n",
    "                mlflow.log_metric(\"initial_u_loss\", initial_u_loss.item(), step=self.epoch)\n",
    "                mlflow.log_metric(\"initial_ϵ_loss\", initial_ϵ_loss.item(), step=self.epoch)\n",
    "                mlflow.log_metric(\"boundary_n_loss\", boundary_n_loss.item(), step=self.epoch)\n",
    "                mlflow.log_metric(\"boundary_u_loss\", boundary_u_loss.item(), step=self.epoch)\n",
    "                mlflow.log_metric(\"boundary_ϵ_loss\", boundary_ϵ_loss.item(), step=self.epoch)\n",
    "                \n",
    "                mlflow.pytorch.log_model(self.model, f\"{self.pars['experiment_name']}_model_epoch_{self.epoch}\")\n",
    "                \n",
    "                if self.pars['plot_training_outputs']:\n",
    "                    self.plot_outputs()\n",
    "            \n",
    "            # training step\n",
    "            self.optimizer.zero_grad()\n",
    "            X_interior = self.sample_interior_points()\n",
    "            X_initial = self.sample_initial_points()\n",
    "            X_boundary = self.sample_boundary_points()\n",
    "            loss, density_loss, vorticity_loss, tpe_loss, initial_n_loss, initial_u_loss, initial_ϵ_loss, boundary_n_loss, boundary_u_loss, boundary_ϵ_loss = self.forward(X_interior, X_initial, X_boundary)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "                \n",
    "            if loss.isnan():\n",
    "                print(f'Epoch: {self.epoch}, Loss: {loss.item():,.4e}')\n",
    "                print(f\"density_loss: {density_loss.item():.4e}, vorticity_loss: {vorticity_loss.item():.4e}, tpe_loss: {tpe_loss.item():.4e}\")\n",
    "                print(f\"initial_n_loss: {initial_n_loss.item():.4e}, initial_u_loss: {initial_u_loss.item():.4e}, initial_ϵ_loss: {initial_ϵ_loss.item():.4e}\")\n",
    "                print(f\"boundary_n_loss: {boundary_n_loss.item():.4e}, boundary_u_loss: {boundary_u_loss.item():.4e}, boundary_ϵ_loss: {boundary_ϵ_loss.item():.4e}\")\n",
    "                print(\"loss is NaN, stopping training...\")\n",
    "                break\n",
    "            \n",
    "        mlflow.pytorch.log_model(self.model, f\"{self.pars['experiment_name']}_model_final\")\n",
    "        \n",
    "        self.save_gif()\n",
    "        \n",
    "        mlflow.end_run()\n",
    "    \n",
    "    def plot_outputs(self):\n",
    "        Y = self(torch.hstack((self.eval_t, self.eval_x)))\n",
    "\n",
    "        n = Y[:, 0].view(-1, 1)\n",
    "        u = Y[:, 1].view(-1, 1)\n",
    "        ϵ = Y[:, 2].view(-1, 1)\n",
    "        \n",
    "        n_x = grad(n, self.eval_x, grad_outputs=torch.ones_like(n), retain_graph=True, create_graph=True)[0]\n",
    "        n_t = grad(n, self.eval_t, grad_outputs=torch.ones_like(n), retain_graph=True)[0]\n",
    "        \n",
    "        n_xx = grad(n_x, self.eval_x, grad_outputs=torch.ones_like(n_x), retain_graph=True)[0]\n",
    "        \n",
    "        u_x = grad(u, self.eval_x, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
    "        u_t = grad(u, self.eval_t, grad_outputs=torch.ones_like(u), retain_graph=True)[0]\n",
    "        \n",
    "        u_xx = grad(u_x, self.eval_x, grad_outputs=torch.ones_like(u_x), retain_graph=True)[0]\n",
    "        \n",
    "        ϵ_x = grad(ϵ, self.eval_x, grad_outputs=torch.ones_like(ϵ), retain_graph=True)[0]\n",
    "        ϵ_t = grad(ϵ, self.eval_t, grad_outputs=torch.ones_like(ϵ), retain_graph=True)[0]\n",
    "        \n",
    "        n = n.view(100, 100).detach().cpu().numpy()\n",
    "        n_x = n_x.view(100, 100).detach().cpu().numpy()\n",
    "        n_t = n_t.view(100, 100).detach().cpu().numpy()\n",
    "        n_xx = n_xx.view(100, 100).detach().cpu().numpy()\n",
    "        \n",
    "        u = u.view(100, 100).detach().cpu().numpy()\n",
    "        u_x = u_x.view(100, 100).detach().cpu().numpy()\n",
    "        u_t = u_t.view(100, 100).detach().cpu().numpy()\n",
    "        u_xx = u_xx.view(100, 100).detach().cpu().numpy()\n",
    "        \n",
    "        ϵ = ϵ.view(100, 100).detach().cpu().numpy()\n",
    "        ϵ_x = ϵ_x.view(100, 100).detach().cpu().numpy()\n",
    "        ϵ_t = ϵ_t.view(100, 100).detach().cpu().numpy()\n",
    "        \n",
    "        if 'n' in self.pars['plot_vars_list']:\n",
    "            self.plot_var(n, 'n')\n",
    "        \n",
    "        if 'n_x' in self.pars['plot_vars_list']:\n",
    "            self.plot_var(n_x, 'n_x')\n",
    "        \n",
    "        if 'n_t' in self.pars['plot_vars_list']:\n",
    "            self.plot_var(n_t, 'n_t')\n",
    "        \n",
    "        if 'n_xx' in self.pars['plot_vars_list']:\n",
    "            self.plot_var(n_xx, 'n_xx')\n",
    "        \n",
    "        if 'u' in self.pars['plot_vars_list']:\n",
    "            self.plot_var(u, 'u')\n",
    "        \n",
    "        if 'u_x' in self.pars['plot_vars_list']:\n",
    "            self.plot_var(u_x, 'u_x')\n",
    "        \n",
    "        if 'u_t' in self.pars['plot_vars_list']:\n",
    "            self.plot_var(u_t, 'u_t')\n",
    "        \n",
    "        if 'u_xx' in self.pars['plot_vars_list']:\n",
    "            self.plot_var(u_xx, 'u_xx')\n",
    "        \n",
    "        if 'ϵ' in self.pars['plot_vars_list']:\n",
    "            self.plot_var(ϵ, 'ϵ')\n",
    "        \n",
    "        if 'ϵ_x' in self.pars['plot_vars_list']:\n",
    "            self.plot_var(ϵ_x, 'ϵ_x')\n",
    "        \n",
    "        if 'ϵ_t' in self.pars['plot_vars_list']:\n",
    "            self.plot_var(ϵ_t, 'ϵ_t')\n",
    "        \n",
    "    def plot_var(self, var, varname):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.plot_surface(self.plot_t, self.plot_x, var, cmap='viridis')\n",
    "        ax.set_xlabel('t')\n",
    "        ax.set_ylabel('x')\n",
    "        ax.set_zlabel(varname)\n",
    "        plt.title(f'Model output {varname}, epoch {self.epoch}')\n",
    "        filename = f\"plots/{self.pars['experiment_name']}/plot_{varname}_epoch_{self.epoch}.png\"\n",
    "        self.plot_files[varname].append(filename)\n",
    "        fig.savefig(filename)\n",
    "        mlflow.log_artifact(filename)\n",
    "        plt.close()\n",
    "        \n",
    "    def save_gif(self):\n",
    "        for varname in self.pars['plot_vars_list']:\n",
    "            gif_filename = f\"plots/{self.pars['experiment_name']}/plot_{varname}.gif\"\n",
    "            with imageio.get_writer(gif_filename, mode='I') as writer:\n",
    "                for filename in self.plot_files[varname]:\n",
    "                    image = imageio.imread(filename)\n",
    "                    writer.append_data(image)\n",
    "                \n",
    "            mlflow.log_artifact(gif_filename)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars = {\n",
    "    'experiment_name': 'simple_pinn_v1',\n",
    "    'layers': 8,\n",
    "    'width': 128,\n",
    "    'lr': 1e-4,\n",
    "    'epochs': 10000,\n",
    "    'eval_interval': 500,\n",
    "    'interior_batch_size': 2048,\n",
    "    'initial_batch_size': 2048,\n",
    "    'boundary_batch_size': 2048,\n",
    "    'x_min': 0.0,\n",
    "    'x_max': 1.0,\n",
    "    't_min': 0.0,\n",
    "    't_max': 10000,\n",
    "    'device': 'cuda',\n",
    "    'plot_training_outputs': True,\n",
    "    'plot_vars_list': ['n', 'n_t', 'n_x', 'n_xx', 'u', 'u_t', 'u_x', 'u_xx', 'ϵ', 'ϵ_t', 'ϵ_x']\n",
    "}\n",
    "pinn = PINN(pars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe6debd5aa2949c9a1493b5848a92f61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training...:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda3/envs/pdenn/lib/python3.12/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([10000, 1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/david/anaconda3/envs/pdenn/lib/python3.12/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([200, 1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, Loss: 8.3007e+03\n",
      "density_loss: 1.6958e-17, vorticity_loss: 1.0688e-17, tpe_loss: 2.4902e+04\n",
      "initial_n_loss: 1.3788e-03, initial_u_loss: 2.4801e-04, initial_ϵ_loss: 1.6819e-03\n",
      "boundary_n_loss: 1.3788e-03, boundary_u_loss: 2.4810e-04, boundary_ϵ_loss: 1.9919e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/02 09:48:30 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "/home/david/anaconda3/envs/pdenn/lib/python3.12/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([2048, 1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 500, Loss: 2.3289e-03\n",
      "density_loss: 9.3811e-18, vorticity_loss: 8.6033e-18, tpe_loss: 6.9785e-03\n",
      "initial_n_loss: 2.1869e-06, initial_u_loss: 1.4286e-09, initial_ϵ_loss: 3.9258e-06\n",
      "boundary_n_loss: 2.2037e-06, boundary_u_loss: 1.4177e-09, boundary_ϵ_loss: 2.8837e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/02 09:49:09 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1000, Loss: 4.0257e-04\n",
      "density_loss: 1.0492e-17, vorticity_loss: 9.3827e-18, tpe_loss: 1.1991e-03\n",
      "initial_n_loss: 2.3209e-06, initial_u_loss: 1.2860e-09, initial_ϵ_loss: 3.9685e-06\n",
      "boundary_n_loss: 2.3356e-06, boundary_u_loss: 1.2356e-09, boundary_ϵ_loss: 2.9254e-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/02 09:49:50 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1500, Loss: 1.8727e-04\n",
      "density_loss: 1.1194e-17, vorticity_loss: 1.0979e-17, tpe_loss: 5.5328e-04\n",
      "initial_n_loss: 2.2606e-06, initial_u_loss: 1.2718e-09, initial_ϵ_loss: 3.9763e-06\n",
      "boundary_n_loss: 2.2751e-06, boundary_u_loss: 1.1792e-09, boundary_ϵ_loss: 1.8928e-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/02 09:50:30 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpinn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 203\u001b[0m, in \u001b[0;36mPINN.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m X_boundary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_boundary_points()\n\u001b[1;32m    202\u001b[0m loss, density_loss, vorticity_loss, tpe_loss, initial_n_loss, initial_u_loss, initial_ϵ_loss, boundary_n_loss, boundary_u_loss, boundary_ϵ_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(X_interior, X_initial, X_boundary)\n\u001b[0;32m--> 203\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss\u001b[38;5;241m.\u001b[39misnan():\n",
      "File \u001b[0;32m~/anaconda3/envs/pdenn/lib/python3.12/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pdenn/lib/python3.12/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pdenn/lib/python3.12/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pinn.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(pinn.pars['epochs']), position=0, leave=True, desc='Training...'): \n",
    "    pinn.epoch = epoch\n",
    "    \n",
    "    # eval\n",
    "    if epoch % pinn.pars['eval_interval'] == 0 or epoch == pinn.pars['epochs'] - 1:\n",
    "        \n",
    "        loss, density_loss, vorticity_loss, tpe_loss, initial_n_loss, initial_u_loss, initial_ϵ_loss, boundary_n_loss, boundary_u_loss, boundary_ϵ_loss \\\n",
    "            = pinn.forward(pinn.eval_X_interior, pinn.eval_X_initial, pinn.eval_X_boundary)\n",
    "        \n",
    "        print()\n",
    "        print(f'Epoch: {pinn.epoch}, Loss: {loss.item():,.4f}')\n",
    "        print(f\"density_loss: {density_loss.item():.4f}, vorticity_loss: {vorticity_loss.item():.4f}, tpe_loss: {tpe_loss.item():.4f}\")\n",
    "        print(f\"initial_n_loss: {initial_n_loss.item():.4f}, initial_u_loss: {initial_u_loss.item():.4f}, initial_ϵ_loss: {initial_ϵ_loss.item():.4f}\")\n",
    "        print(f\"boundary_n_loss: {boundary_n_loss.item():.4f}, boundary_u_loss: {boundary_u_loss.item():.4f}, boundary_ϵ_loss: {boundary_ϵ_loss.item():.4f}\")\n",
    "        \n",
    "        # if pinn.pars['plot_training_outputs']:\n",
    "        #     pinn.plot_outputs()\n",
    "    \n",
    "    # training step\n",
    "    pinn.optimizer.zero_grad()\n",
    "    X_interior = pinn.sample_interior_points()\n",
    "    X_initial = pinn.sample_initial_points()\n",
    "    X_boundary = pinn.sample_boundary_points()\n",
    "    loss, density_loss, vorticity_loss, tpe_loss, initial_n_loss, initial_u_loss, initial_ϵ_loss, boundary_n_loss, boundary_u_loss, boundary_ϵ_loss = pinn.forward(X_interior, X_initial, X_boundary)\n",
    "    \n",
    "        \n",
    "    if loss.isnan():\n",
    "        print(f'Epoch: {pinn.epoch}, Loss: {loss.item():,.4f}')\n",
    "        print(f\"density_loss: {density_loss.item():.4f}, vorticity_loss: {vorticity_loss.item():.4f}, tpe_loss: {tpe_loss.item():.4f}\")\n",
    "        print(f\"initial_n_loss: {initial_n_loss.item():.4f}, initial_u_loss: {initial_u_loss.item():.4f}, initial_ϵ_loss: {initial_ϵ_loss.item():.4f}\")\n",
    "        print(f\"boundary_n_loss: {boundary_n_loss.item():.4f}, boundary_u_loss: {boundary_u_loss.item():.4f}, boundary_ϵ_loss: {boundary_ϵ_loss.item():.4f}\")\n",
    "        print(\"loss is NaN, stopping training...\")\n",
    "        break\n",
    "    \n",
    "    else:\n",
    "        loss.backward()\n",
    "        pinn.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_interior = X_interior[:, 1].reshape(-1, 1)\n",
    "t_interior = X_interior[:, 0].reshape(-1, 1)\n",
    "\n",
    "Y_interior = pinn(torch.hstack((t_interior, x_interior)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_interior = Y_interior[:, 0].reshape(-1, 1)\n",
    "u_interior = Y_interior[:, 1].reshape(-1, 1)\n",
    "ϵ_interior = Y_interior[:, 2].reshape(-1, 1)\n",
    "\n",
    "w = compute_w(C_χ, l, ϵ_interior, α, a_u, u_interior)\n",
    "\n",
    "n_x_interior = grad(n_interior, x_interior, grad_outputs=torch.ones_like(n_interior), retain_graph=True, create_graph=True)[0]\n",
    "u_x_interior = grad(u_interior, x_interior, grad_outputs=torch.ones_like(u_interior), retain_graph=True, create_graph=True)[0]\n",
    "ϵ_x_interior = grad(ϵ_interior, x_interior, grad_outputs=torch.ones_like(ϵ_interior), retain_graph=True, create_graph=True)[0]\n",
    "ϵ_t_interior = grad(ϵ_interior, t_interior, grad_outputs=torch.ones_like(ϵ_interior), retain_graph=True, create_graph=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpe = pde_tpe(x_interior, ϵ_interior, n_x_interior, u_x_interior, ϵ_t_interior, ϵ_x_interior, l, β, Λ, ϵ_c, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_interior[336], ϵ_interior[336], n_x_interior[336], u_x_interior[336], ϵ_x_interior[336], ϵ_t_interior[336], tpe[336]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate = l**2 * torch.sqrt(ϵ_interior) * ϵ_x_interior\n",
    "intermediate.isnan().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ϵ_interior[336]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ϵ_interior**(-0.5))[336]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ϵ_interior**(-0.5)*ϵ_x_interior).isnan().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = grad(ϵ_x_interior, x_interior, grad_outputs=torch.ones_like(ϵ_x_interior), retain_graph=True, create_graph=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnan().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_x = grad(intermediate, x_interior, grad_outputs=torch.ones_like(intermediate), retain_graph=True, create_graph=True)[0]\n",
    "intermediate_x.isnan().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.autograd.detect_anomaly(check_nan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(tpe.shape[0]):\n",
    "    if tpe[i].isnan():\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in pinn.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_interior = pinn.sample_interior_points()\n",
    "X_initial = pinn.sample_initial_points()\n",
    "X_boundary = pinn.sample_boundary_points()\n",
    "\n",
    "t_interior = X_interior[:, 0].reshape(-1, 1)\n",
    "x_interior = X_interior[:, 1].reshape(-1, 1)\n",
    "t_initial = X_initial[:, 0].reshape(-1, 1)\n",
    "x_initial = X_initial[:, 1].reshape(-1, 1)\n",
    "t_boundary = X_boundary[:, 0].reshape(-1, 1)\n",
    "x_boundary = X_boundary[:, 1].reshape(-1, 1)\n",
    "\n",
    "# forward pass\n",
    "Y_interior = pinn.model(torch.hstack((t_interior, x_interior)))\n",
    "Y_initial = pinn.model(torch.hstack((t_initial, x_initial)))\n",
    "Y_boundary = pinn.model(torch.hstack((t_boundary, x_boundary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X_interior: {X_interior}\")\n",
    "print(f\"X_initial: {X_initial}\")\n",
    "print(f\"X_boundary: {X_boundary}\")\n",
    "print(f\"t_interior: {t_interior}\")\n",
    "print(f\"x_interior: {x_interior}\")\n",
    "print(f\"t_initial: {t_initial}\")\n",
    "print(f\"x_initial: {x_initial}\")\n",
    "print(f\"t_boundary: {t_boundary}\")\n",
    "print(f\"x_boundary: {x_boundary}\")\n",
    "print(f\"Y_interior: {Y_interior}\")\n",
    "print(f\"Y_initial: {Y_initial}\")\n",
    "print(f\"Y_boundary: {Y_boundary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_interior = Y_interior[:, 0].reshape(-1, 1)\n",
    "u_interior = Y_interior[:, 1].reshape(-1, 1)\n",
    "ϵ_interior = Y_interior[:, 2].reshape(-1, 1)\n",
    "\n",
    "n_initial = Y_initial[:, 0].reshape(-1, 1)\n",
    "u_initial = Y_initial[:, 1].reshape(-1, 1)\n",
    "ϵ_initial = Y_initial[:, 2].reshape(-1, 1)\n",
    "\n",
    "n_boundary = Y_boundary[:, 0].reshape(-1, 1)\n",
    "u_boundary = Y_boundary[:, 1].reshape(-1, 1)\n",
    "ϵ_boundary = Y_boundary[:, 2].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"n_interior: {n_interior}\")\n",
    "print(f\"u_interior: {u_interior}\")\n",
    "print(f\"ϵ_interior: {ϵ_interior}\")\n",
    "print(f\"n_initial: {n_initial}\")\n",
    "print(f\"u_initial: {u_initial}\")\n",
    "print(f\"ϵ_initial: {ϵ_initial}\")\n",
    "print(f\"n_boundary: {n_boundary}\")\n",
    "print(f\"u_boundary: {u_boundary}\")\n",
    "print(f\"ϵ_boundary: {ϵ_boundary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_x_interior = grad(n_interior, x_interior, grad_outputs=torch.ones_like(n_interior), retain_graph=True, create_graph=True)[0]\n",
    "n_t_interior = grad(n_interior, t_interior, grad_outputs=torch.ones_like(n_interior), retain_graph=True, create_graph=True)[0]\n",
    "\n",
    "n_xx_interior = grad(n_x_interior, x_interior, grad_outputs=torch.ones_like(n_x_interior), retain_graph=True, create_graph=True)[0]\n",
    "\n",
    "u_x_interior = grad(u_interior, x_interior, grad_outputs=torch.ones_like(u_interior), retain_graph=True, create_graph=True)[0]\n",
    "u_t_interior = grad(u_interior, t_interior, grad_outputs=torch.ones_like(u_interior), retain_graph=True, create_graph=True)[0]\n",
    "\n",
    "u_xx_interior = grad(u_x_interior, x_interior, grad_outputs=torch.ones_like(u_x_interior), retain_graph=True, create_graph=True)[0]\n",
    "\n",
    "ϵ_x_interior = grad(ϵ_interior, x_interior, grad_outputs=torch.ones_like(ϵ_interior), retain_graph=True, create_graph=True)[0]\n",
    "ϵ_t_interior = grad(ϵ_interior, t_interior, grad_outputs=torch.ones_like(ϵ_interior), retain_graph=True, create_graph=True)[0]\n",
    "\n",
    "ϵ_x_boundary = grad(ϵ_boundary, x_boundary, grad_outputs=torch.ones_like(ϵ_boundary), retain_graph=True, create_graph=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"n_x_interior: {n_x_interior}\")\n",
    "print(f\"n_t_interior: {n_t_interior}\")\n",
    "print(f\"n_xx_interior: {n_xx_interior}\")\n",
    "print(f\"u_x_interior: {u_x_interior}\")\n",
    "print(f\"u_t_interior: {u_t_interior}\")\n",
    "print(f\"u_xx_interior: {u_xx_interior}\")\n",
    "print(f\"ϵ_x_interior: {ϵ_x_interior}\")\n",
    "print(f\"ϵ_t_interior: {ϵ_t_interior}\")\n",
    "print(f\"ϵ_x_boundary: {ϵ_x_boundary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = compute_w(C_χ, l, ϵ_interior, α, a_u, u_interior)\n",
    "\n",
    "density_loss = pde_mean_density(x_interior, n_t_interior, n_x_interior, n_xx_interior, ϵ_interior, l, α, D_c)\n",
    "vorticity_loss = pde_mean_vorticity(x_interior, ϵ_interior, n_x_interior, u_t_interior, u_xx_interior, l, α, μ_c, w)\n",
    "tpe_loss = pde_tpe(x_interior, ϵ_interior, n_x_interior, u_x_interior, ϵ_t_interior, ϵ_x_interior, l, β, Λ, ϵ_c, w)\n",
    "interior_loss = (density_loss + vorticity_loss + tpe_loss).mean()\n",
    "\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "initial_n_loss = mse(n_initial_cond(t_initial), n_initial)\n",
    "initial_u_loss = mse(u_initial_cond(t_initial), u_initial)\n",
    "initial_ϵ_loss = mse(ϵ_initial_cond(t_initial), ϵ_initial)\n",
    "initial_loss = (initial_n_loss + initial_u_loss + initial_ϵ_loss)\n",
    "\n",
    "boundary_n_loss = mse(n_boundary_cond(t_boundary, x_boundary), n_boundary)\n",
    "boundary_u_loss = mse(u_boundary_cond(t_boundary, x_boundary), u_boundary)\n",
    "boundary_ϵ_loss = mse(ϵ_x_boundary_cond(t_boundary, x_boundary), ϵ_x_boundary)\n",
    "boundary_loss = (boundary_n_loss + boundary_u_loss + boundary_ϵ_loss)\n",
    "total_loss = interior_loss + initial_loss + boundary_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"w: {w}\")\n",
    "print(f\"density_loss: {density_loss.mean().item()}, vorticity_loss: {vorticity_loss.mean().item()}, tpe_loss: {tpe_loss.mean().item()}\")\n",
    "print(f\"initial_n_loss: {initial_n_loss.item()}, initial_u_loss: {initial_u_loss.item()}, initial_ϵ_loss: {initial_ϵ_loss.item()}\")\n",
    "print(f\"boundary_n_loss: {boundary_n_loss.item()}, boundary_u_loss: {boundary_u_loss.item()}, boundary_ϵ_loss: {boundary_ϵ_loss.item()}\")\n",
    "print(f\"total_loss: {total_loss.item()}\")\n",
    "print(f\"interior_loss: {interior_loss.item()}\")\n",
    "print(f\"initial_loss: {initial_loss.item()}\")\n",
    "print(f\"boundary_loss: {boundary_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_boundary, n_boundary_cond(t_boundary, x_boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse(n_boundary_cond(t_boundary, x_boundary), n_boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate = l**2 * torch.sqrt(ϵ_interior) * ϵ_x_interior\n",
    "intermediate_x = grad(intermediate, x_interior, grad_outputs=torch.ones_like(intermediate), retain_graph=True, create_graph=True)[0]\n",
    "\n",
    "tpe_loss = torch.abs(ϵ_t_interior - β * intermediate_x - Λ * (w * (n_x_interior - u_x_interior)**2 - ϵ_interior**(3/2) / ϵ_c**0.5 + ϵ_interior))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(w * (n_x_interior - u_x_interior)**2 - ϵ_interior**(3/2) / ϵ_c**0.5 + ϵ_interior)*4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ϵ_interior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ϵ_interior**1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(-0.4184)**1.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdenn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
