{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PINN Implementation of Ashourvan & Diamond Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import grad\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 1.0     # not provided by paper, need to check relation with Λ \n",
    "α = 6.0\n",
    "D_c = 0.78\n",
    "C_χ = 0.95\n",
    "a_u = 1.0\n",
    "μ_c = 0.78\n",
    "β = 0.1\n",
    "Λ = 4000.0\n",
    "ϵ_c = 6.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_i = 5.1\n",
    "ϵ_i = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_params = {\n",
    "    'l': l,\n",
    "    'α': α,\n",
    "    'D_c': D_c,\n",
    "    'C_χ': C_χ,\n",
    "    'a_u': a_u,\n",
    "    'μ_c': μ_c,\n",
    "    'β': β,\n",
    "    'Λ': Λ,\n",
    "    'ϵ_c': ϵ_c,\n",
    "    'g_i': g_i,\n",
    "    'ϵ_i': ϵ_i\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define PDEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define repeated calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_w(C_χ, l, ϵ, α, a_u, u):\n",
    "    return C_χ * l**2 * ϵ / torch.sqrt(α**2 + a_u * u**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic equation for mean density\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pde_mean_density(x, n_t, n_x, n_xx, ϵ, l, α, D_c):    \n",
    "    intermediate = l**2 * ϵ * n_x / α\n",
    "    intermediate_x = grad(intermediate, x, grad_outputs=torch.ones_like(intermediate), retain_graph=True, create_graph=True)[0]\n",
    "    \n",
    "    return (n_t - intermediate_x - D_c * n_xx)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic equation for mean vorticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pde_mean_vorticity(x, ϵ, n_x, u_t, u_xx, l, α, μ_c, w):    \n",
    "    intermediate = (l**2 * ϵ / α - w) * n_x\n",
    "    intermediate_x = grad(intermediate, x, grad_outputs=torch.ones_like(intermediate), retain_graph=True, create_graph=True)[0]\n",
    "    \n",
    "    return (u_t - intermediate_x - w * u_xx - μ_c * u_xx)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic equation for turbulent potential entrosphy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pde_tpe(x, ϵ, n_x, u_x, ϵ_t, ϵ_x, l, β, Λ, ϵ_c, w):\n",
    "    intermediate = l**2 * torch.sqrt(ϵ) * ϵ_x\n",
    "    intermediate_x = grad(intermediate, x, grad_outputs=torch.ones_like(intermediate), retain_graph=True, create_graph=True)[0]\n",
    "    \n",
    "    return (ϵ_t - β * intermediate_x - Λ * (w * (n_x - u_x)**2 - ϵ**(3/2) / ϵ_c**0.5 + ϵ))**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Initial Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_initial_cond(t, x):\n",
    "    return -g_i * x\n",
    "\n",
    "def u_initial_cond(t, x):\n",
    "    return torch.zeros(x.shape, device=x.device.type)\n",
    "\n",
    "def ϵ_initial_cond(t, x):\n",
    "    return torch.full(x.shape, ϵ_i, device=x.device.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Boundary Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_boundary_cond(t, x):\n",
    "    out = torch.full(x.shape, -g_i, device=x.device.type)\n",
    "    out = out * x\n",
    "    \n",
    "    return out\n",
    "\n",
    "def u_boundary_cond(t, x):\n",
    "    return torch.zeros(x.shape, device=x.device.type)\n",
    "\n",
    "\n",
    "def ϵ_x_boundary_cond(t, x):\n",
    "    return torch.zeros(x.shape, device=x.device.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PINN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOutputLayer(nn.Module):\n",
    "    def __init__(self, pars):\n",
    "        super(CustomOutputLayer, self).__init__()\n",
    "        self.n = nn.Sequential(nn.Linear(pars['width'], 1))\n",
    "        self.u = nn.Sequential(nn.Linear(pars['width'], 1))\n",
    "        self.ϵ = nn.Sequential(nn.Linear(pars['width'], 1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.hstack((self.n(x), self.u(x), torch.abs(self.ϵ(x) + 1e-2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    def __init__(self, pars: dict):\n",
    "        super().__init__()\n",
    "        self.pars = pars\n",
    "        \n",
    "        self.modules = [nn.BatchNorm1d(2), nn.Linear(2, self.pars['width'])] # nn.LayerNorm(2)\n",
    "        for i in range(self.pars['layers'] - 1):\n",
    "            # self.modules.append(nn.LayerNorm(self.pars['width']))\n",
    "            self.modules.append(nn.GELU())\n",
    "            self.modules.append(nn.Linear(self.pars['width'], self.pars['width']))\n",
    "        \n",
    "        # self.modules.append(nn.LayerNorm(self.pars['width']))\n",
    "        self.modules.append(CustomOutputLayer(pars))\n",
    "        \n",
    "        self.model = nn.Sequential(*self.modules)\n",
    "        self.model.to(self.pars['device'])\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(params=self.model.parameters(), lr=self.pars['lr'])\n",
    "        self.num_params = sum([len(params) for params in [p for p in self.model.parameters()]])\n",
    "        \n",
    "        self.epoch = 0\n",
    "        \n",
    "        t = np.linspace(self.pars['t_min'], self.pars['t_max'], 100)\n",
    "        x = np.linspace(self.pars['x_min'], self.pars['x_max'], 100)\n",
    "        \n",
    "        self.stage_interval = self.pars['epochs']//self.pars['num_stages']\n",
    "\n",
    "        self.eval_t, self.eval_x = np.meshgrid(t, x)\n",
    "        self.eval_t = torch.Tensor(self.eval_t).reshape(-1, 1).to(self.pars['device'])\n",
    "        self.eval_x = torch.Tensor(self.eval_x).reshape(-1, 1).to(self.pars['device'])\n",
    "        \n",
    "        self.eval_t.requires_grad_()\n",
    "        self.eval_x.requires_grad_()\n",
    "        \n",
    "        eval_t_interior, eval_x_interior = np.meshgrid(t[1:-1], x[1:-1])\n",
    "        eval_t_interior = torch.Tensor(eval_t_interior).reshape(-1, 1).to(self.pars['device'])\n",
    "        eval_x_interior = torch.Tensor(eval_x_interior).reshape(-1, 1).to(self.pars['device'])\n",
    "        \n",
    "        self.eval_X_interior = torch.hstack((eval_t_interior, eval_x_interior))\n",
    "        self.eval_X_interior.requires_grad_()\n",
    "        \n",
    "        eval_t_initial = torch.zeros_like(self.eval_x)\n",
    "        self.eval_X_initial = torch.hstack((eval_t_initial, self.eval_x))\n",
    "        self.eval_X_initial.requires_grad_()\n",
    "        \n",
    "        eval_t_boundary = torch.Tensor(np.vstack([t, t])).reshape(-1, 1).to(self.pars['device'])\n",
    "        eval_x_boundary = torch.Tensor(np.vstack([x[0] * np.ones_like(t), x[-1] * np.ones_like(t)])).reshape(-1, 1).to(self.pars['device'])\n",
    "        \n",
    "        self.eval_X_boundary = torch.hstack((eval_t_boundary, eval_x_boundary))\n",
    "        self.eval_X_boundary.requires_grad_()\n",
    "        \n",
    "        self.plot_t = self.eval_t.view(100, 100).detach().cpu().numpy()\n",
    "        self.plot_x = self.eval_x.view(100, 100).detach().cpu().numpy()\n",
    "        \n",
    "        self.plot_files = {}\n",
    "        \n",
    "        if 'plot_vars_list' in self.pars:\n",
    "            for varname in self.pars['plot_vars_list']:\n",
    "                self.plot_files[varname] = []\n",
    "        \n",
    "    def __call__(self, X):\n",
    "        return self.model(X)\n",
    "        \n",
    "    def sample_interior_points(self, percent):\n",
    "        t = torch.empty((self.pars['interior_batch_size'], 1), device=self.pars['device']).uniform_(self.pars['t_min'], percent * self.pars['t_max'])\n",
    "        x1 = torch.empty((self.pars['interior_batch_size']//2, 1), device=self.pars['device']).uniform_(self.pars['x_min'], self.pars['x_min'] + percent * (self.pars['x_max'] - self.pars['x_min']))\n",
    "        x2 = torch.empty((self.pars['interior_batch_size']//2, 1), device=self.pars['device']).uniform_(self.pars['x_min'] + (1 - percent) * (self.pars['x_max'] - self.pars['x_min']), self.pars['x_max'])\n",
    "        x = torch.vstack((x1, x2))\n",
    "        X_interior = torch.cat((t, x), 1)\n",
    "        X_interior.requires_grad_()\n",
    "        \n",
    "        return X_interior\n",
    "    \n",
    "    def sample_initial_points(self):\n",
    "        t = torch.zeros(self.pars['initial_batch_size'], 1, device=self.pars['device'])\n",
    "        x = torch.empty((self.pars['initial_batch_size'], 1), device=self.pars['device']).uniform_(self.pars['x_min'], self.pars['x_max'])\n",
    "        X_initial = torch.cat((t, x), 1)\n",
    "        X_initial.requires_grad_()\n",
    "        \n",
    "        return X_initial\n",
    "    \n",
    "    def sample_boundary_points(self):\n",
    "        options = torch.tensor([self.pars['x_min'], self.pars['x_max']], device=self.pars['device'])\n",
    "        \n",
    "        t = torch.empty((self.pars['boundary_batch_size'], 1), device=self.pars['device']).uniform_(self.pars['t_min'], self.pars['t_max'])\n",
    "        x = options[torch.randint(0, 2, (self.pars['boundary_batch_size'], 1), device=self.pars['device'])]\n",
    "        X_boundary = torch.cat((t, x), 1)\n",
    "        X_boundary.requires_grad_()\n",
    "        \n",
    "        return X_boundary\n",
    "    \n",
    "    def forward(self, X_interior, X_initial, X_boundary):\n",
    "        # X shape: (batch_size, 2), where 2nd dimension is [t, x]\n",
    "        # Y shape: (batch_size, 3), where 2nd dimension is [n, u, ϵ]\n",
    "        \n",
    "        t_interior = X_interior[:, 0].reshape(-1, 1)\n",
    "        x_interior = X_interior[:, 1].reshape(-1, 1)\n",
    "        t_initial = X_initial[:, 0].reshape(-1, 1)\n",
    "        x_initial = X_initial[:, 1].reshape(-1, 1)\n",
    "        t_boundary = X_boundary[:, 0].reshape(-1, 1)\n",
    "        x_boundary = X_boundary[:, 1].reshape(-1, 1)\n",
    "        \n",
    "        # forward pass\n",
    "        Y_interior = self.model(torch.hstack((t_interior, x_interior)))\n",
    "        Y_initial = self.model(torch.hstack((t_initial, x_initial)))\n",
    "        Y_boundary = self.model(torch.hstack((t_boundary, x_boundary)))\n",
    "        \n",
    "        n_interior = Y_interior[:, 0].reshape(-1, 1)\n",
    "        u_interior = Y_interior[:, 1].reshape(-1, 1)\n",
    "        ϵ_interior = Y_interior[:, 2].reshape(-1, 1)\n",
    "        \n",
    "        n_initial = Y_initial[:, 0].reshape(-1, 1)\n",
    "        u_initial = Y_initial[:, 1].reshape(-1, 1)\n",
    "        ϵ_initial = Y_initial[:, 2].reshape(-1, 1)\n",
    "        \n",
    "        n_boundary = Y_boundary[:, 0].reshape(-1, 1)\n",
    "        u_boundary = Y_boundary[:, 1].reshape(-1, 1)\n",
    "        ϵ_boundary = Y_boundary[:, 2].reshape(-1, 1)\n",
    "        \n",
    "        n_x_interior = grad(n_interior, x_interior, grad_outputs=torch.ones_like(n_interior), retain_graph=True, create_graph=True)[0]\n",
    "        n_t_interior = grad(n_interior, t_interior, grad_outputs=torch.ones_like(n_interior), retain_graph=True, create_graph=True)[0]\n",
    "        \n",
    "        n_xx_interior = grad(n_x_interior, x_interior, grad_outputs=torch.ones_like(n_x_interior), retain_graph=True, create_graph=True)[0]\n",
    "        \n",
    "        u_x_interior = grad(u_interior, x_interior, grad_outputs=torch.ones_like(u_interior), retain_graph=True, create_graph=True)[0]\n",
    "        u_t_interior = grad(u_interior, t_interior, grad_outputs=torch.ones_like(u_interior), retain_graph=True, create_graph=True)[0]\n",
    "        \n",
    "        u_xx_interior = grad(u_x_interior, x_interior, grad_outputs=torch.ones_like(u_x_interior), retain_graph=True, create_graph=True)[0]\n",
    "        \n",
    "        ϵ_x_interior = grad(ϵ_interior, x_interior, grad_outputs=torch.ones_like(ϵ_interior), retain_graph=True, create_graph=True)[0]\n",
    "        ϵ_t_interior = grad(ϵ_interior, t_interior, grad_outputs=torch.ones_like(ϵ_interior), retain_graph=True, create_graph=True)[0]\n",
    "        \n",
    "        ϵ_x_boundary = grad(ϵ_boundary, x_boundary, grad_outputs=torch.ones_like(ϵ_boundary), retain_graph=True, create_graph=True)[0]\n",
    "        \n",
    "        w = compute_w(C_χ, l, ϵ_interior, α, a_u, u_interior)\n",
    "        \n",
    "        density_loss = pde_mean_density(x_interior, n_t_interior, n_x_interior, n_xx_interior, ϵ_interior, l, α, D_c).mean()\n",
    "        vorticity_loss = pde_mean_vorticity(x_interior, ϵ_interior, n_x_interior, u_t_interior, u_xx_interior, l, α, μ_c, w).mean()\n",
    "        tpe_loss = pde_tpe(x_interior, ϵ_interior, n_x_interior, u_x_interior, ϵ_t_interior, ϵ_x_interior, l, β, Λ, ϵ_c, w).mean()\n",
    "        interior_loss = (density_loss + vorticity_loss + tpe_loss)/3\n",
    "        \n",
    "        mse = nn.MSELoss()\n",
    "        \n",
    "        initial_n_loss = mse(n_initial_cond(t_initial, x_initial), n_initial)\n",
    "        initial_u_loss = mse(u_initial_cond(t_initial, x_initial), u_initial)\n",
    "        initial_ϵ_loss = mse(ϵ_initial_cond(t_initial, x_initial), ϵ_initial)\n",
    "        initial_loss = (initial_n_loss + initial_u_loss + initial_ϵ_loss)/3\n",
    "        \n",
    "        boundary_n_loss = mse(n_boundary_cond(t_boundary, x_boundary), n_boundary)\n",
    "        boundary_u_loss = mse(u_boundary_cond(t_boundary, x_boundary), u_boundary)\n",
    "        boundary_ϵ_loss = mse(ϵ_x_boundary_cond(t_boundary, x_boundary), ϵ_x_boundary)\n",
    "        boundary_loss = (boundary_n_loss + boundary_u_loss + boundary_ϵ_loss)/3\n",
    "        total_loss = interior_loss + initial_loss + boundary_loss\n",
    "        \n",
    "        return total_loss, density_loss, vorticity_loss, tpe_loss, initial_n_loss, initial_u_loss, initial_ϵ_loss, boundary_n_loss, boundary_u_loss, boundary_ϵ_loss\n",
    "    \n",
    "    def train(self):\n",
    "        cwd = os.getcwd()\n",
    "        plot_dirs = os.path.join(cwd, f'plots/{self.pars[\"experiment_name\"]}')\n",
    "\n",
    "        if not os.path.isdir(plot_dirs):\n",
    "            os.makedirs(plot_dirs)\n",
    "        \n",
    "        mlflow.set_experiment(self.pars['experiment_name'])\n",
    "        mlflow.start_run()\n",
    "        \n",
    "        mlflow.log_param(\"physical_params\", physical_params)\n",
    "        mlflow.log_param(\"model_params\", self.pars)\n",
    "        \n",
    "        \n",
    "        stage_percent = 0\n",
    "        for epoch in tqdm(range(self.pars['epochs']), position=0, leave=True, desc='Training...'): \n",
    "            self.epoch = epoch\n",
    "            \n",
    "            # eval\n",
    "            if epoch % self.pars['eval_interval'] == 0 or epoch == self.pars['epochs'] - 1:\n",
    "                \n",
    "                loss, density_loss, vorticity_loss, tpe_loss, initial_n_loss, initial_u_loss, initial_ϵ_loss, boundary_n_loss, boundary_u_loss, boundary_ϵ_loss \\\n",
    "                    = self.forward(self.eval_X_interior, self.eval_X_initial, self.eval_X_boundary)\n",
    "                \n",
    "                print()\n",
    "                print(f'Epoch: {self.epoch}, Loss: {loss.item():,.4e}')\n",
    "                print(f\"density_loss: {density_loss.item():.4e}, vorticity_loss: {vorticity_loss.item():.4e}, tpe_loss: {tpe_loss.item():.4e}\")\n",
    "                print(f\"initial_n_loss: {initial_n_loss.item():.4e}, initial_u_loss: {initial_u_loss.item():.4e}, initial_ϵ_loss: {initial_ϵ_loss.item():.4e}\")\n",
    "                print(f\"boundary_n_loss: {boundary_n_loss.item():.4e}, boundary_u_loss: {boundary_u_loss.item():.4e}, boundary_ϵ_loss: {boundary_ϵ_loss.item():.4e}\")\n",
    "                \n",
    "                mlflow.log_metric(\"total_loss\", loss.item(), step=self.epoch)\n",
    "                mlflow.log_metric(\"density_loss\", density_loss.item(), step=self.epoch)\n",
    "                mlflow.log_metric(\"vorticity_loss\", vorticity_loss.item(), step=self.epoch)\n",
    "                mlflow.log_metric(\"tpe_loss\", tpe_loss.item(), step=self.epoch)\n",
    "                mlflow.log_metric(\"initial_n_loss\", initial_n_loss.item(), step=self.epoch)\n",
    "                mlflow.log_metric(\"initial_u_loss\", initial_u_loss.item(), step=self.epoch)\n",
    "                mlflow.log_metric(\"initial_ϵ_loss\", initial_ϵ_loss.item(), step=self.epoch)\n",
    "                mlflow.log_metric(\"boundary_n_loss\", boundary_n_loss.item(), step=self.epoch)\n",
    "                mlflow.log_metric(\"boundary_u_loss\", boundary_u_loss.item(), step=self.epoch)\n",
    "                mlflow.log_metric(\"boundary_ϵ_loss\", boundary_ϵ_loss.item(), step=self.epoch)\n",
    "                \n",
    "                mlflow.pytorch.log_model(self.model, f\"{self.pars['experiment_name']}_model_epoch_{self.epoch}\")\n",
    "                \n",
    "                if self.pars['plot_training_outputs']:\n",
    "                    self.plot_outputs()\n",
    "            \n",
    "            # training step\n",
    "            self.optimizer.zero_grad()\n",
    "            if epoch % self.stage_interval == 0:\n",
    "                stage_percent += 1/self.pars['num_stages']\n",
    "                print(f\"Training PINN with {stage_percent*100:.2f}% of interior points\")\n",
    "                X_interior = self.sample_interior_points(stage_percent)\n",
    "                X_initial = self.sample_initial_points()\n",
    "                X_boundary = self.sample_boundary_points()\n",
    "            loss, density_loss, vorticity_loss, tpe_loss, initial_n_loss, initial_u_loss, initial_ϵ_loss, boundary_n_loss, boundary_u_loss, boundary_ϵ_loss = self.forward(X_interior, X_initial, X_boundary)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "                \n",
    "            if loss.isnan():\n",
    "                print(f'Epoch: {self.epoch}, Loss: {loss.item():,.4e}')\n",
    "                print(f\"density_loss: {density_loss.item():.4e}, vorticity_loss: {vorticity_loss.item():.4e}, tpe_loss: {tpe_loss.item():.4e}\")\n",
    "                print(f\"initial_n_loss: {initial_n_loss.item():.4e}, initial_u_loss: {initial_u_loss.item():.4e}, initial_ϵ_loss: {initial_ϵ_loss.item():.4e}\")\n",
    "                print(f\"boundary_n_loss: {boundary_n_loss.item():.4e}, boundary_u_loss: {boundary_u_loss.item():.4e}, boundary_ϵ_loss: {boundary_ϵ_loss.item():.4e}\")\n",
    "                print(\"loss is NaN, stopping training...\")\n",
    "                break\n",
    "            \n",
    "        mlflow.pytorch.log_model(self.model, f\"{self.pars['experiment_name']}_model_final\")\n",
    "        \n",
    "        self.save_gif()\n",
    "        \n",
    "        mlflow.end_run()\n",
    "    \n",
    "    def plot_outputs(self):\n",
    "        Y = self(torch.hstack((self.eval_t, self.eval_x)))\n",
    "\n",
    "        n = Y[:, 0].view(-1, 1)\n",
    "        u = Y[:, 1].view(-1, 1)\n",
    "        ϵ = Y[:, 2].view(-1, 1)\n",
    "        \n",
    "        n_x = grad(n, self.eval_x, grad_outputs=torch.ones_like(n), retain_graph=True, create_graph=True)[0]\n",
    "        n_t = grad(n, self.eval_t, grad_outputs=torch.ones_like(n), retain_graph=True)[0]\n",
    "        \n",
    "        n_xx = grad(n_x, self.eval_x, grad_outputs=torch.ones_like(n_x), retain_graph=True)[0]\n",
    "        \n",
    "        u_x = grad(u, self.eval_x, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
    "        u_t = grad(u, self.eval_t, grad_outputs=torch.ones_like(u), retain_graph=True)[0]\n",
    "        \n",
    "        u_xx = grad(u_x, self.eval_x, grad_outputs=torch.ones_like(u_x), retain_graph=True)[0]\n",
    "        \n",
    "        ϵ_x = grad(ϵ, self.eval_x, grad_outputs=torch.ones_like(ϵ), retain_graph=True)[0]\n",
    "        ϵ_t = grad(ϵ, self.eval_t, grad_outputs=torch.ones_like(ϵ), retain_graph=True)[0]\n",
    "        \n",
    "        n = n.view(100, 100).detach().cpu().numpy()\n",
    "        n_x = n_x.view(100, 100).detach().cpu().numpy()\n",
    "        n_t = n_t.view(100, 100).detach().cpu().numpy()\n",
    "        n_xx = n_xx.view(100, 100).detach().cpu().numpy()\n",
    "        \n",
    "        u = u.view(100, 100).detach().cpu().numpy()\n",
    "        u_x = u_x.view(100, 100).detach().cpu().numpy()\n",
    "        u_t = u_t.view(100, 100).detach().cpu().numpy()\n",
    "        u_xx = u_xx.view(100, 100).detach().cpu().numpy()\n",
    "        \n",
    "        ϵ = ϵ.view(100, 100).detach().cpu().numpy()\n",
    "        ϵ_x = ϵ_x.view(100, 100).detach().cpu().numpy()\n",
    "        ϵ_t = ϵ_t.view(100, 100).detach().cpu().numpy()\n",
    "        \n",
    "        if 'n' in self.pars['plot_vars_list']:\n",
    "            self.plot_var(n, 'n')\n",
    "        \n",
    "        if 'n_x' in self.pars['plot_vars_list']:\n",
    "            self.plot_var(n_x, 'n_x')\n",
    "        \n",
    "        if 'n_t' in self.pars['plot_vars_list']:\n",
    "            self.plot_var(n_t, 'n_t')\n",
    "        \n",
    "        if 'n_xx' in self.pars['plot_vars_list']:\n",
    "            self.plot_var(n_xx, 'n_xx')\n",
    "        \n",
    "        if 'u' in self.pars['plot_vars_list']:\n",
    "            self.plot_var(u, 'u')\n",
    "        \n",
    "        if 'u_x' in self.pars['plot_vars_list']:\n",
    "            self.plot_var(u_x, 'u_x')\n",
    "        \n",
    "        if 'u_t' in self.pars['plot_vars_list']:\n",
    "            self.plot_var(u_t, 'u_t')\n",
    "        \n",
    "        if 'u_xx' in self.pars['plot_vars_list']:\n",
    "            self.plot_var(u_xx, 'u_xx')\n",
    "        \n",
    "        if 'ϵ' in self.pars['plot_vars_list']:\n",
    "            self.plot_var(ϵ, 'ϵ')\n",
    "        \n",
    "        if 'ϵ_x' in self.pars['plot_vars_list']:\n",
    "            self.plot_var(ϵ_x, 'ϵ_x')\n",
    "        \n",
    "        if 'ϵ_t' in self.pars['plot_vars_list']:\n",
    "            self.plot_var(ϵ_t, 'ϵ_t')\n",
    "        \n",
    "    def plot_var(self, var, varname):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.plot_surface(self.plot_t, self.plot_x, var, cmap='viridis')\n",
    "        ax.set_xlabel('t')\n",
    "        ax.set_ylabel('x')\n",
    "        ax.set_zlabel(varname)\n",
    "        plt.title(f'Model output {varname}, epoch {self.epoch}')\n",
    "        filename = f\"plots/{self.pars['experiment_name']}/plot_{varname}_epoch_{self.epoch}.png\"\n",
    "        self.plot_files[varname].append(filename)\n",
    "        fig.savefig(filename)\n",
    "        mlflow.log_artifact(filename)\n",
    "        plt.close()\n",
    "        \n",
    "    def save_gif(self):\n",
    "        for varname in self.pars['plot_vars_list']:\n",
    "            gif_filename = f\"plots/{self.pars['experiment_name']}/plot_{varname}.gif\"\n",
    "            with imageio.get_writer(gif_filename, mode='I') as writer:\n",
    "                for filename in self.plot_files[varname]:\n",
    "                    image = imageio.imread(filename)\n",
    "                    writer.append_data(image)\n",
    "                \n",
    "            mlflow.log_artifact(gif_filename)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars = {\n",
    "    'experiment_name': 'simple_pinn_multistage_training_v1',\n",
    "    'layers': 4,\n",
    "    'width': 64,\n",
    "    'lr': 1e-4,\n",
    "    'epochs': 50000,\n",
    "    'eval_interval': 5000,\n",
    "    'interior_batch_size': 2048,\n",
    "    'initial_batch_size': 2048,\n",
    "    'boundary_batch_size': 2048,\n",
    "    'x_min': 0.0,\n",
    "    'x_max': 1.0,\n",
    "    't_min': 0.0,\n",
    "    't_max': 10000,\n",
    "    'device': 'cuda',\n",
    "    'plot_training_outputs': True,\n",
    "    'plot_vars_list': ['n', 'n_t', 'n_x', 'n_xx', 'u', 'u_t', 'u_x', 'u_xx', 'ϵ', 'ϵ_t', 'ϵ_x'],\n",
    "    'num_stages': 10\n",
    "}\n",
    "pinn = PINN(pars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b807d7824da74a9aaf1849fec5199173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training...:   0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, Loss: 1.0539e+03\n",
      "density_loss: 1.9098e-09, vorticity_loss: 3.4090e-12, tpe_loss: 3.1409e+03\n",
      "initial_n_loss: 8.2539e+00, initial_u_loss: 1.4526e-03, initial_ϵ_loss: 6.4043e-05\n",
      "boundary_n_loss: 1.2552e+01, boundary_u_loss: 1.4390e-03, boundary_ϵ_loss: 1.0799e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/25 20:16:30 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PINN with 10.00% of interior points\n",
      "Epoch: 291, Loss: nan\n",
      "density_loss: 7.8639e-11, vorticity_loss: 3.1813e-11, tpe_loss: nan\n",
      "initial_n_loss: 7.4175e+00, initial_u_loss: 2.0249e-05, initial_ϵ_loss: 2.6989e-06\n",
      "boundary_n_loss: 1.1902e+01, boundary_u_loss: 1.3032e-04, boundary_ϵ_loss: 3.2475e-06\n",
      "loss is NaN, stopping training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/25 20:16:50 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    }
   ],
   "source": [
    "pinn.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars = {\n",
    "    'experiment_name': 'simple_pinn_multistage_training_v1',\n",
    "    'layers': 8,\n",
    "    'width': 128,\n",
    "    'lr': 1e-4,\n",
    "    'epochs': 10000,\n",
    "    'eval_interval': 500,\n",
    "    'interior_batch_size': 2048,\n",
    "    'initial_batch_size': 2048,\n",
    "    'boundary_batch_size': 2048,\n",
    "    'x_min': 0.0,\n",
    "    'x_max': 1.0,\n",
    "    't_min': 0.0,\n",
    "    't_max': 10000,\n",
    "    'device': 'cuda',\n",
    "    'plot_training_outputs': True,\n",
    "    'plot_vars_list': ['n', 'n_t', 'n_x', 'n_xx', 'u', 'u_t', 'u_x', 'u_xx', 'ϵ', 'ϵ_t', 'ϵ_x'],\n",
    "    'num_stages': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(0,pars['epochs'],pars['epochs']//pars['num_stages']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdenn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
