{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PINN Implementation of Ashourvan & Diamond Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import grad\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 1.0     # not provided by paper, need to check relation with Λ \n",
    "α = 6.0\n",
    "D_c = 0.78\n",
    "C_χ = 0.95\n",
    "a_u = 1.0\n",
    "μ_c = 0.78\n",
    "β = 0.1\n",
    "Λ = 4000.0\n",
    "ϵ_c = 6.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_i = 5.1\n",
    "ϵ_i = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_params = {\n",
    "    'l': l,\n",
    "    'α': α,\n",
    "    'D_c': D_c,\n",
    "    'C_χ': C_χ,\n",
    "    'a_u': a_u,\n",
    "    'μ_c': μ_c,\n",
    "    'β': β,\n",
    "    'Λ': Λ,\n",
    "    'ϵ_c': ϵ_c,\n",
    "    'g_i': g_i,\n",
    "    'ϵ_i': ϵ_i\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define PDEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define repeated calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_w(C_χ, l, ϵ, α, a_u, u):\n",
    "    return C_χ * l**2 * ϵ / torch.sqrt(α**2 + a_u * u**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic equation for mean density\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pde_mean_density(x, n_t, n_x, n_xx, ϵ, l, α, D_c):    \n",
    "    intermediate = l**2 * ϵ * n_x / α\n",
    "    intermediate_x = grad(intermediate, x, grad_outputs=torch.ones_like(intermediate), retain_graph=True, create_graph=True)[0]\n",
    "    \n",
    "    return (n_t - intermediate_x - D_c * n_xx)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic equation for mean vorticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pde_mean_vorticity(x, ϵ, n_x, u_t, u_xx, l, α, μ_c, w):    \n",
    "    intermediate = (l**2 * ϵ / α - w) * n_x\n",
    "    intermediate_x = grad(intermediate, x, grad_outputs=torch.ones_like(intermediate), retain_graph=True, create_graph=True)[0]\n",
    "    \n",
    "    return (u_t - intermediate_x - w * u_xx - μ_c * u_xx)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic equation for turbulent potential entrosphy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pde_tpe(x, ϵ, n_x, u_x, ϵ_t, ϵ_x, l, β, Λ, ϵ_c, w):\n",
    "    intermediate = l**2 * torch.sqrt(ϵ) * ϵ_x\n",
    "    intermediate_x = grad(intermediate, x, grad_outputs=torch.ones_like(intermediate), retain_graph=True, create_graph=True)[0]\n",
    "    \n",
    "    return (ϵ_t - β * intermediate_x - Λ * (w * (n_x - u_x)**2 - ϵ**(3/2) / ϵ_c**0.5 + ϵ))**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Initial Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_initial_cond(t, x):\n",
    "    return -g_i * x\n",
    "\n",
    "def u_initial_cond(t, x):\n",
    "    return torch.zeros(x.shape, device=x.device.type)\n",
    "\n",
    "def ϵ_initial_cond(t, x):\n",
    "    return torch.full(x.shape, ϵ_i, device=x.device.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Boundary Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_boundary_cond(t, x):\n",
    "    out = torch.full(x.shape, -g_i, device=x.device.type)\n",
    "    out = out * x\n",
    "    \n",
    "    return out\n",
    "\n",
    "def u_boundary_cond(t, x):\n",
    "    return torch.zeros(x.shape, device=x.device.type)\n",
    "\n",
    "\n",
    "def ϵ_x_boundary_cond(t, x):\n",
    "    return torch.zeros(x.shape, device=x.device.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PINN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOutputLayer(nn.Module):\n",
    "    def __init__(self, pars):\n",
    "        super(CustomOutputLayer, self).__init__()\n",
    "        self.n = nn.Sequential(nn.Linear(pars['width'], 1))\n",
    "        self.u = nn.Sequential(nn.Linear(pars['width'], 1))\n",
    "        self.ϵ = nn.Sequential(nn.Linear(pars['width'], 1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.hstack((self.n(x), self.u(x), torch.abs(self.ϵ(x) + 1e-2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    def __init__(self, pars: dict):\n",
    "        super().__init__()\n",
    "        self.pars = pars\n",
    "        \n",
    "        self.modules = [nn.BatchNorm1d(2), nn.Linear(2, self.pars['width'])] # nn.LayerNorm(2)\n",
    "        for i in range(self.pars['layers'] - 1):\n",
    "            # self.modules.append(nn.LayerNorm(self.pars['width']))\n",
    "            self.modules.append(nn.GELU())\n",
    "            self.modules.append(nn.Linear(self.pars['width'], self.pars['width']))\n",
    "        \n",
    "        # self.modules.append(nn.LayerNorm(self.pars['width']))\n",
    "        self.modules.append(CustomOutputLayer(pars))\n",
    "        \n",
    "        self.model = nn.Sequential(*self.modules)\n",
    "        self.model.to(self.pars['device'])\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(params=self.model.parameters(), lr=self.pars['lr'])\n",
    "        self.num_params = sum([len(params) for params in [p for p in self.model.parameters()]])\n",
    "        \n",
    "        self.epoch = 0\n",
    "        \n",
    "        t = np.linspace(self.pars['t_min'], self.pars['t_max'], 100)\n",
    "        x = np.linspace(self.pars['x_min'], self.pars['x_max'], 100)\n",
    "        \n",
    "        self.stage_interval = self.pars['epochs']//self.pars['num_stages']\n",
    "\n",
    "        self.eval_t, self.eval_x = np.meshgrid(t, x)\n",
    "        self.eval_t = torch.Tensor(self.eval_t).reshape(-1, 1).to(self.pars['device'])\n",
    "        self.eval_x = torch.Tensor(self.eval_x).reshape(-1, 1).to(self.pars['device'])\n",
    "        \n",
    "        self.eval_t.requires_grad_()\n",
    "        self.eval_x.requires_grad_()\n",
    "        \n",
    "        eval_t_interior, eval_x_interior = np.meshgrid(t[1:-1], x[1:-1])\n",
    "        eval_t_interior = torch.Tensor(eval_t_interior).reshape(-1, 1).to(self.pars['device'])\n",
    "        eval_x_interior = torch.Tensor(eval_x_interior).reshape(-1, 1).to(self.pars['device'])\n",
    "        \n",
    "        self.eval_X_interior = torch.hstack((eval_t_interior, eval_x_interior))\n",
    "        self.eval_X_interior.requires_grad_()\n",
    "        \n",
    "        eval_t_initial = torch.zeros_like(self.eval_x)\n",
    "        self.eval_X_initial = torch.hstack((eval_t_initial, self.eval_x))\n",
    "        self.eval_X_initial.requires_grad_()\n",
    "        \n",
    "        eval_t_boundary = torch.Tensor(np.vstack([t, t])).reshape(-1, 1).to(self.pars['device'])\n",
    "        eval_x_boundary = torch.Tensor(np.vstack([x[0] * np.ones_like(t), x[-1] * np.ones_like(t)])).reshape(-1, 1).to(self.pars['device'])\n",
    "        \n",
    "        self.eval_X_boundary = torch.hstack((eval_t_boundary, eval_x_boundary))\n",
    "        self.eval_X_boundary.requires_grad_()\n",
    "        \n",
    "        self.plot_t = self.eval_t.view(100, 100).detach().cpu().numpy()\n",
    "        self.plot_x = self.eval_x.view(100, 100).detach().cpu().numpy()\n",
    "        \n",
    "        self.plot_files = {}\n",
    "        \n",
    "        if 'plot_vars_list' in self.pars:\n",
    "            for varname in self.pars['plot_vars_list']:\n",
    "                self.plot_files[varname] = []\n",
    "        \n",
    "    def __call__(self, X):\n",
    "        return self.model(X)\n",
    "        \n",
    "    def sample_interior_points(self, percent):\n",
    "        t = torch.empty((self.pars['interior_batch_size'], 1), device=self.pars['device']).uniform_(self.pars['t_min'], percent * self.pars['t_max'])\n",
    "        x1 = torch.empty((self.pars['interior_batch_size']//2, 1), device=self.pars['device']).uniform_(self.pars['x_min'], self.pars['x_min'] + percent * (self.pars['x_max'] - self.pars['x_min']))\n",
    "        x2 = torch.empty((self.pars['interior_batch_size']//2, 1), device=self.pars['device']).uniform_(self.pars['x_min'] + (1 - percent) * (self.pars['x_max'] - self.pars['x_min']), self.pars['x_max'])\n",
    "        x = torch.vstack((x1, x2))\n",
    "        X_interior = torch.cat((t, x), 1)\n",
    "        X_interior.requires_grad_()\n",
    "        \n",
    "        return X_interior\n",
    "    \n",
    "    def sample_initial_points(self):\n",
    "        t = torch.zeros(self.pars['initial_batch_size'], 1, device=self.pars['device'])\n",
    "        x = torch.empty((self.pars['initial_batch_size'], 1), device=self.pars['device']).uniform_(self.pars['x_min'], self.pars['x_max'])\n",
    "        X_initial = torch.cat((t, x), 1)\n",
    "        X_initial.requires_grad_()\n",
    "        \n",
    "        return X_initial\n",
    "    \n",
    "    def sample_boundary_points(self):\n",
    "        options = torch.tensor([self.pars['x_min'], self.pars['x_max']], device=self.pars['device'])\n",
    "        \n",
    "        t = torch.empty((self.pars['boundary_batch_size'], 1), device=self.pars['device']).uniform_(self.pars['t_min'], self.pars['t_max'])\n",
    "        x = options[torch.randint(0, 2, (self.pars['boundary_batch_size'], 1), device=self.pars['device'])]\n",
    "        X_boundary = torch.cat((t, x), 1)\n",
    "        X_boundary.requires_grad_()\n",
    "        \n",
    "        return X_boundary\n",
    "    \n",
    "    def forward(self, X_interior, X_initial, X_boundary):\n",
    "        # X shape: (batch_size, 2), where 2nd dimension is [t, x]\n",
    "        # Y shape: (batch_size, 3), where 2nd dimension is [n, u, ϵ]\n",
    "        \n",
    "        t_interior = X_interior[:, 0].reshape(-1, 1)\n",
    "        x_interior = X_interior[:, 1].reshape(-1, 1)\n",
    "        t_initial = X_initial[:, 0].reshape(-1, 1)\n",
    "        x_initial = X_initial[:, 1].reshape(-1, 1)\n",
    "        t_boundary = X_boundary[:, 0].reshape(-1, 1)\n",
    "        x_boundary = X_boundary[:, 1].reshape(-1, 1)\n",
    "        \n",
    "        # forward pass\n",
    "        Y_interior = self.model(torch.hstack((t_interior, x_interior)))\n",
    "        Y_initial = self.model(torch.hstack((t_initial, x_initial)))\n",
    "        Y_boundary = self.model(torch.hstack((t_boundary, x_boundary)))\n",
    "        \n",
    "        n_interior = Y_interior[:, 0].reshape(-1, 1)\n",
    "        u_interior = Y_interior[:, 1].reshape(-1, 1)\n",
    "        ϵ_interior = Y_interior[:, 2].reshape(-1, 1)\n",
    "        \n",
    "        n_initial = Y_initial[:, 0].reshape(-1, 1)\n",
    "        u_initial = Y_initial[:, 1].reshape(-1, 1)\n",
    "        ϵ_initial = Y_initial[:, 2].reshape(-1, 1)\n",
    "        \n",
    "        n_boundary = Y_boundary[:, 0].reshape(-1, 1)\n",
    "        u_boundary = Y_boundary[:, 1].reshape(-1, 1)\n",
    "        ϵ_boundary = Y_boundary[:, 2].reshape(-1, 1)\n",
    "        \n",
    "        n_x_interior = grad(n_interior, x_interior, grad_outputs=torch.ones_like(n_interior), retain_graph=True, create_graph=True)[0]\n",
    "        n_t_interior = grad(n_interior, t_interior, grad_outputs=torch.ones_like(n_interior), retain_graph=True, create_graph=True)[0]\n",
    "        \n",
    "        n_xx_interior = grad(n_x_interior, x_interior, grad_outputs=torch.ones_like(n_x_interior), retain_graph=True, create_graph=True)[0]\n",
    "        \n",
    "        u_x_interior = grad(u_interior, x_interior, grad_outputs=torch.ones_like(u_interior), retain_graph=True, create_graph=True)[0]\n",
    "        u_t_interior = grad(u_interior, t_interior, grad_outputs=torch.ones_like(u_interior), retain_graph=True, create_graph=True)[0]\n",
    "        \n",
    "        u_xx_interior = grad(u_x_interior, x_interior, grad_outputs=torch.ones_like(u_x_interior), retain_graph=True, create_graph=True)[0]\n",
    "        \n",
    "        ϵ_x_interior = grad(ϵ_interior, x_interior, grad_outputs=torch.ones_like(ϵ_interior), retain_graph=True, create_graph=True)[0]\n",
    "        ϵ_t_interior = grad(ϵ_interior, t_interior, grad_outputs=torch.ones_like(ϵ_interior), retain_graph=True, create_graph=True)[0]\n",
    "        \n",
    "        ϵ_x_boundary = grad(ϵ_boundary, x_boundary, grad_outputs=torch.ones_like(ϵ_boundary), retain_graph=True, create_graph=True)[0]\n",
    "        \n",
    "        w = compute_w(C_χ, l, ϵ_interior, α, a_u, u_interior)\n",
    "        \n",
    "        density_loss = pde_mean_density(x_interior, n_t_interior, n_x_interior, n_xx_interior, ϵ_interior, l, α, D_c).mean()\n",
    "        vorticity_loss = pde_mean_vorticity(x_interior, ϵ_interior, n_x_interior, u_t_interior, u_xx_interior, l, α, μ_c, w).mean()\n",
    "        tpe_loss = pde_tpe(x_interior, ϵ_interior, n_x_interior, u_x_interior, ϵ_t_interior, ϵ_x_interior, l, β, Λ, ϵ_c, w).mean()\n",
    "        interior_loss = (density_loss + vorticity_loss + tpe_loss)/3\n",
    "        \n",
    "        mse = nn.MSELoss()\n",
    "        \n",
    "        initial_n_loss = mse(n_initial_cond(t_initial, x_initial), n_initial)\n",
    "        initial_u_loss = mse(u_initial_cond(t_initial, x_initial), u_initial)\n",
    "        initial_ϵ_loss = mse(ϵ_initial_cond(t_initial, x_initial), ϵ_initial)\n",
    "        initial_loss = (initial_n_loss + initial_u_loss + initial_ϵ_loss)/3\n",
    "        \n",
    "        boundary_n_loss = mse(n_boundary_cond(t_boundary, x_boundary), n_boundary)\n",
    "        boundary_u_loss = mse(u_boundary_cond(t_boundary, x_boundary), u_boundary)\n",
    "        boundary_ϵ_loss = mse(ϵ_x_boundary_cond(t_boundary, x_boundary), ϵ_x_boundary)\n",
    "        boundary_loss = (boundary_n_loss + boundary_u_loss + boundary_ϵ_loss)/3\n",
    "        total_loss = interior_loss + initial_loss + boundary_loss\n",
    "        \n",
    "        return total_loss, density_loss, vorticity_loss, tpe_loss, initial_n_loss, initial_u_loss, initial_ϵ_loss, boundary_n_loss, boundary_u_loss, boundary_ϵ_loss\n",
    "    \n",
    "    def train(self):\n",
    "        cwd = os.getcwd()\n",
    "        plot_dirs = os.path.join(cwd, f'plots/{self.pars[\"experiment_name\"]}')\n",
    "\n",
    "        if not os.path.isdir(plot_dirs):\n",
    "            os.makedirs(plot_dirs)\n",
    "        \n",
    "        mlflow.set_experiment(self.pars['experiment_name'])\n",
    "        mlflow.start_run()\n",
    "        \n",
    "        mlflow.log_param(\"physical_params\", physical_params)\n",
    "        mlflow.log_param(\"model_params\", self.pars)\n",
    "        \n",
    "        \n",
    "        stage_percent = 0\n",
    "        for epoch in tqdm(range(self.pars['epochs']), position=0, leave=True, desc='Training...'): \n",
    "            self.epoch = epoch\n",
    "            \n",
    "            # eval\n",
    "            if epoch % self.pars['eval_interval'] == 0 or epoch == self.pars['epochs'] - 1:\n",
    "                \n",
    "                loss, density_loss, vorticity_loss, tpe_loss, initial_n_loss, initial_u_loss, initial_ϵ_loss, boundary_n_loss, boundary_u_loss, boundary_ϵ_loss \\\n",
    "                    = self.forward(self.eval_X_interior, self.eval_X_initial, self.eval_X_boundary)\n",
    "                \n",
    "                print()\n",
    "                print(f'Epoch: {self.epoch}, Loss: {loss.item():,.4e}')\n",
    "                print(f\"density_loss: {density_loss.item():.4e}, vorticity_loss: {vorticity_loss.item():.4e}, tpe_loss: {tpe_loss.item():.4e}\")\n",
    "                print(f\"initial_n_loss: {initial_n_loss.item():.4e}, initial_u_loss: {initial_u_loss.item():.4e}, initial_ϵ_loss: {initial_ϵ_loss.item():.4e}\")\n",
    "                print(f\"boundary_n_loss: {boundary_n_loss.item():.4e}, boundary_u_loss: {boundary_u_loss.item():.4e}, boundary_ϵ_loss: {boundary_ϵ_loss.item():.4e}\")\n",
    "                \n",
    "                mlflow.log_metric(\"total_loss\", loss.item(), step=self.epoch)\n",
    "                mlflow.log_metric(\"density_loss\", density_loss.item(), step=self.epoch)\n",
    "                mlflow.log_metric(\"vorticity_loss\", vorticity_loss.item(), step=self.epoch)\n",
    "                mlflow.log_metric(\"tpe_loss\", tpe_loss.item(), step=self.epoch)\n",
    "                mlflow.log_metric(\"initial_n_loss\", initial_n_loss.item(), step=self.epoch)\n",
    "                mlflow.log_metric(\"initial_u_loss\", initial_u_loss.item(), step=self.epoch)\n",
    "                mlflow.log_metric(\"initial_ϵ_loss\", initial_ϵ_loss.item(), step=self.epoch)\n",
    "                mlflow.log_metric(\"boundary_n_loss\", boundary_n_loss.item(), step=self.epoch)\n",
    "                mlflow.log_metric(\"boundary_u_loss\", boundary_u_loss.item(), step=self.epoch)\n",
    "                mlflow.log_metric(\"boundary_ϵ_loss\", boundary_ϵ_loss.item(), step=self.epoch)\n",
    "                \n",
    "                mlflow.pytorch.log_model(self.model, f\"{self.pars['experiment_name']}_model_epoch_{self.epoch}\")\n",
    "                \n",
    "                if self.pars['plot_training_outputs']:\n",
    "                    self.plot_outputs()\n",
    "            \n",
    "            # training step\n",
    "            self.optimizer.zero_grad()\n",
    "            if epoch % self.stage_interval == 0:\n",
    "                stage_percent += 1/self.pars['num_stages']\n",
    "                print(f\"Training PINN with {stage_percent*100:.2f}% of interior points\")\n",
    "                X_interior = self.sample_interior_points(stage_percent)\n",
    "                X_initial = self.sample_initial_points()\n",
    "                X_boundary = self.sample_boundary_points()\n",
    "            loss, density_loss, vorticity_loss, tpe_loss, initial_n_loss, initial_u_loss, initial_ϵ_loss, boundary_n_loss, boundary_u_loss, boundary_ϵ_loss = self.forward(X_interior, X_initial, X_boundary)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "                \n",
    "            if loss.isnan():\n",
    "                print(f'Epoch: {self.epoch}, Loss: {loss.item():,.4e}')\n",
    "                print(f\"density_loss: {density_loss.item():.4e}, vorticity_loss: {vorticity_loss.item():.4e}, tpe_loss: {tpe_loss.item():.4e}\")\n",
    "                print(f\"initial_n_loss: {initial_n_loss.item():.4e}, initial_u_loss: {initial_u_loss.item():.4e}, initial_ϵ_loss: {initial_ϵ_loss.item():.4e}\")\n",
    "                print(f\"boundary_n_loss: {boundary_n_loss.item():.4e}, boundary_u_loss: {boundary_u_loss.item():.4e}, boundary_ϵ_loss: {boundary_ϵ_loss.item():.4e}\")\n",
    "                print(\"loss is NaN, stopping training...\")\n",
    "                break\n",
    "            \n",
    "        mlflow.pytorch.log_model(self.model, f\"{self.pars['experiment_name']}_model_final\")\n",
    "        \n",
    "        self.save_gif()\n",
    "        \n",
    "        mlflow.end_run()\n",
    "    \n",
    "    def plot_outputs(self):\n",
    "        Y = self(torch.hstack((self.eval_t, self.eval_x)))\n",
    "\n",
    "        n = Y[:, 0].view(-1, 1)\n",
    "        u = Y[:, 1].view(-1, 1)\n",
    "        ϵ = Y[:, 2].view(-1, 1)\n",
    "        \n",
    "        n_x = grad(n, self.eval_x, grad_outputs=torch.ones_like(n), retain_graph=True, create_graph=True)[0]\n",
    "        n_t = grad(n, self.eval_t, grad_outputs=torch.ones_like(n), retain_graph=True)[0]\n",
    "        \n",
    "        n_xx = grad(n_x, self.eval_x, grad_outputs=torch.ones_like(n_x), retain_graph=True)[0]\n",
    "        \n",
    "        u_x = grad(u, self.eval_x, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
    "        u_t = grad(u, self.eval_t, grad_outputs=torch.ones_like(u), retain_graph=True)[0]\n",
    "        \n",
    "        u_xx = grad(u_x, self.eval_x, grad_outputs=torch.ones_like(u_x), retain_graph=True)[0]\n",
    "        \n",
    "        ϵ_x = grad(ϵ, self.eval_x, grad_outputs=torch.ones_like(ϵ), retain_graph=True)[0]\n",
    "        ϵ_t = grad(ϵ, self.eval_t, grad_outputs=torch.ones_like(ϵ), retain_graph=True)[0]\n",
    "        \n",
    "        n = n.view(100, 100).detach().cpu().numpy()\n",
    "        n_x = n_x.view(100, 100).detach().cpu().numpy()\n",
    "        n_t = n_t.view(100, 100).detach().cpu().numpy()\n",
    "        n_xx = n_xx.view(100, 100).detach().cpu().numpy()\n",
    "        \n",
    "        u = u.view(100, 100).detach().cpu().numpy()\n",
    "        u_x = u_x.view(100, 100).detach().cpu().numpy()\n",
    "        u_t = u_t.view(100, 100).detach().cpu().numpy()\n",
    "        u_xx = u_xx.view(100, 100).detach().cpu().numpy()\n",
    "        \n",
    "        ϵ = ϵ.view(100, 100).detach().cpu().numpy()\n",
    "        ϵ_x = ϵ_x.view(100, 100).detach().cpu().numpy()\n",
    "        ϵ_t = ϵ_t.view(100, 100).detach().cpu().numpy()\n",
    "        \n",
    "        if 'n' in self.pars['plot_vars_list']:\n",
    "            self.plot_var(n, 'n')\n",
    "        \n",
    "        if 'n_x' in self.pars['plot_vars_list']:\n",
    "            self.plot_var(n_x, 'n_x')\n",
    "        \n",
    "        if 'n_t' in self.pars['plot_vars_list']:\n",
    "            self.plot_var(n_t, 'n_t')\n",
    "        \n",
    "        if 'n_xx' in self.pars['plot_vars_list']:\n",
    "            self.plot_var(n_xx, 'n_xx')\n",
    "        \n",
    "        if 'u' in self.pars['plot_vars_list']:\n",
    "            self.plot_var(u, 'u')\n",
    "        \n",
    "        if 'u_x' in self.pars['plot_vars_list']:\n",
    "            self.plot_var(u_x, 'u_x')\n",
    "        \n",
    "        if 'u_t' in self.pars['plot_vars_list']:\n",
    "            self.plot_var(u_t, 'u_t')\n",
    "        \n",
    "        if 'u_xx' in self.pars['plot_vars_list']:\n",
    "            self.plot_var(u_xx, 'u_xx')\n",
    "        \n",
    "        if 'ϵ' in self.pars['plot_vars_list']:\n",
    "            self.plot_var(ϵ, 'ϵ')\n",
    "        \n",
    "        if 'ϵ_x' in self.pars['plot_vars_list']:\n",
    "            self.plot_var(ϵ_x, 'ϵ_x')\n",
    "        \n",
    "        if 'ϵ_t' in self.pars['plot_vars_list']:\n",
    "            self.plot_var(ϵ_t, 'ϵ_t')\n",
    "        \n",
    "    def plot_var(self, var, varname):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.plot_surface(self.plot_t, self.plot_x, var, cmap='viridis')\n",
    "        ax.set_xlabel('t')\n",
    "        ax.set_ylabel('x')\n",
    "        ax.set_zlabel(varname)\n",
    "        plt.title(f'Model output {varname}, epoch {self.epoch}')\n",
    "        filename = f\"plots/{self.pars['experiment_name']}/plot_{varname}_epoch_{self.epoch}.png\"\n",
    "        self.plot_files[varname].append(filename)\n",
    "        fig.savefig(filename)\n",
    "        mlflow.log_artifact(filename)\n",
    "        plt.close()\n",
    "        \n",
    "    def save_gif(self):\n",
    "        for varname in self.pars['plot_vars_list']:\n",
    "            gif_filename = f\"plots/{self.pars['experiment_name']}/plot_{varname}.gif\"\n",
    "            with imageio.get_writer(gif_filename, mode='I') as writer:\n",
    "                for filename in self.plot_files[varname]:\n",
    "                    image = imageio.imread(filename)\n",
    "                    writer.append_data(image)\n",
    "                \n",
    "            mlflow.log_artifact(gif_filename)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars = {\n",
    "    'experiment_name': 'simple_pinn_multistage_training_v1',\n",
    "    'layers': 4,\n",
    "    'width': 64,\n",
    "    'lr': 1e-4,\n",
    "    'epochs': 100000,\n",
    "    'eval_interval': 5000,\n",
    "    'interior_batch_size': 2048,\n",
    "    'initial_batch_size': 2048,\n",
    "    'boundary_batch_size': 2048,\n",
    "    'x_min': 0.0,\n",
    "    'x_max': 1.0,\n",
    "    't_min': 0.0,\n",
    "    't_max': 10000,\n",
    "    'device': 'cuda',\n",
    "    'plot_training_outputs': True,\n",
    "    'plot_vars_list': ['n', 'n_t', 'n_x', 'n_xx', 'u', 'u_t', 'u_x', 'u_xx', 'ϵ', 'ϵ_t', 'ϵ_x'],\n",
    "    'num_stages': 10\n",
    "}\n",
    "pinn = PINN(pars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2bc7ac37afb4aa4b0857e396f3242a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training...:   0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, Loss: 4.7720e+04\n",
      "density_loss: 9.8346e-09, vorticity_loss: 5.0727e-11, tpe_loss: 1.4314e+05\n",
      "initial_n_loss: 8.3916e+00, initial_u_loss: 3.5081e-03, initial_ϵ_loss: 1.1911e-02\n",
      "boundary_n_loss: 1.2664e+01, boundary_u_loss: 4.2775e-03, boundary_ϵ_loss: 5.8873e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/25 23:27:58 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PINN with 10.00% of interior points\n",
      "\n",
      "Epoch: 5000, Loss: 3.3449e+00\n",
      "density_loss: 6.2894e-09, vorticity_loss: 2.9387e-11, tpe_loss: 2.2161e+00\n",
      "initial_n_loss: 1.9819e+00, initial_u_loss: 5.5131e-05, initial_ϵ_loss: 3.1854e-06\n",
      "boundary_n_loss: 5.8365e+00, boundary_u_loss: 1.9735e-04, boundary_ϵ_loss: 2.0299e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/25 23:32:13 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 10000, Loss: 6.4688e-01\n",
      "density_loss: 6.5850e-08, vorticity_loss: 1.9939e-10, tpe_loss: 1.3560e+00\n",
      "initial_n_loss: 2.6358e-01, initial_u_loss: 1.1414e-04, initial_ϵ_loss: 3.3996e-06\n",
      "boundary_n_loss: 3.2086e-01, boundary_u_loss: 1.0818e-04, boundary_ϵ_loss: 1.0965e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/25 23:36:17 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PINN with 20.00% of interior points\n",
      "\n",
      "Epoch: 15000, Loss: 2.5918e-01\n",
      "density_loss: 7.2721e-08, vorticity_loss: 1.9808e-10, tpe_loss: 2.9146e-01\n",
      "initial_n_loss: 2.4275e-01, initial_u_loss: 4.0774e-06, initial_ϵ_loss: 3.8530e-06\n",
      "boundary_n_loss: 2.4329e-01, boundary_u_loss: 3.3978e-05, boundary_ϵ_loss: 2.4743e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/25 23:40:20 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 20000, Loss: 2.0361e-01\n",
      "density_loss: 1.0968e-07, vorticity_loss: 3.0056e-10, tpe_loss: 2.4517e-01\n",
      "initial_n_loss: 1.7960e-01, initial_u_loss: 5.7099e-05, initial_ϵ_loss: 3.6802e-06\n",
      "boundary_n_loss: 1.8580e-01, boundary_u_loss: 2.1148e-04, boundary_ϵ_loss: 2.1857e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/25 23:44:21 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PINN with 30.00% of interior points\n",
      "\n",
      "Epoch: 25000, Loss: 1.2923e-01\n",
      "density_loss: 8.2854e-08, vorticity_loss: 5.9985e-10, tpe_loss: 1.0388e-01\n",
      "initial_n_loss: 1.0070e-01, initial_u_loss: 6.8342e-04, initial_ϵ_loss: 3.8437e-06\n",
      "boundary_n_loss: 1.8031e-01, boundary_u_loss: 2.1180e-03, boundary_ϵ_loss: 9.2127e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/25 23:48:22 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 30000, Loss: 1.0274e-01\n",
      "density_loss: 7.2740e-08, vorticity_loss: 7.9974e-10, tpe_loss: 5.0673e-02\n",
      "initial_n_loss: 8.3477e-02, initial_u_loss: 1.6249e-03, initial_ϵ_loss: 3.8694e-06\n",
      "boundary_n_loss: 1.6925e-01, boundary_u_loss: 3.1968e-03, boundary_ϵ_loss: 6.4117e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/25 23:52:25 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PINN with 40.00% of interior points\n",
      "\n",
      "Epoch: 35000, Loss: 1.0473e-01\n",
      "density_loss: 3.1158e-08, vorticity_loss: 7.7587e-10, tpe_loss: 5.1418e-02\n",
      "initial_n_loss: 8.7265e-02, initial_u_loss: 1.3716e-03, initial_ϵ_loss: 3.8958e-06\n",
      "boundary_n_loss: 1.7027e-01, boundary_u_loss: 3.8683e-03, boundary_ϵ_loss: 3.9431e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/25 23:56:29 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpinn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 212\u001b[0m, in \u001b[0;36mPINN.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m     X_boundary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_boundary_points()\n\u001b[1;32m    211\u001b[0m loss, density_loss, vorticity_loss, tpe_loss, initial_n_loss, initial_u_loss, initial_ϵ_loss, boundary_n_loss, boundary_u_loss, boundary_ϵ_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(X_interior, X_initial, X_boundary)\n\u001b[0;32m--> 212\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss\u001b[38;5;241m.\u001b[39misnan():\n",
      "File \u001b[0;32m~/anaconda3/envs/pdenn/lib/python3.12/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pdenn/lib/python3.12/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pdenn/lib/python3.12/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pinn.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars = {\n",
    "    'experiment_name': 'simple_pinn_multistage_training_v1',\n",
    "    'layers': 8,\n",
    "    'width': 128,\n",
    "    'lr': 1e-4,\n",
    "    'epochs': 10000,\n",
    "    'eval_interval': 500,\n",
    "    'interior_batch_size': 2048,\n",
    "    'initial_batch_size': 2048,\n",
    "    'boundary_batch_size': 2048,\n",
    "    'x_min': 0.0,\n",
    "    'x_max': 1.0,\n",
    "    't_min': 0.0,\n",
    "    't_max': 10000,\n",
    "    'device': 'cuda',\n",
    "    'plot_training_outputs': True,\n",
    "    'plot_vars_list': ['n', 'n_t', 'n_x', 'n_xx', 'u', 'u_t', 'u_x', 'u_xx', 'ϵ', 'ϵ_t', 'ϵ_x'],\n",
    "    'num_stages': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(0,pars['epochs'],pars['epochs']//pars['num_stages']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdenn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
